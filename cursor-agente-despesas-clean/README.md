# Sistema de Classifica√ß√£o de Despesas

Sistema inteligente para classifica√ß√£o autom√°tica da **Natureza do Gasto** e campos derivados (tipo, parcelas, compartilhamento) usando regras determin√≠sticas, similaridade TF-IDF e modelos de Machine Learning.

## üöÄ Quick Start

### Pronto para uso: Docker Compose (Recomendado)

O ambiente est√° configurado para rodar com **Docker Compose** na porta **8081**

#### Comandos essenciais:

```bash
# 1. Subir o ambiente (primeira vez)
docker-compose up -d

# 2. Ver logs em tempo real
docker-compose logs -f

# 3. Parar o ambiente
docker-compose down

# 4. Reiniciar (ap√≥s mudan√ßas no c√≥digo)
docker-compose restart

# 5. Rebuild completo (ap√≥s mudan√ßas no Dockerfile ou depend√™ncias)
docker-compose up -d --build

# 6. Health check
curl http://localhost:8081/health
```

#### Testar classifica√ß√£o:
```bash
curl -X POST "http://localhost:8081/v1/classify" \
  -H "Content-Type: application/json" \
  -d @app/samples/tx_single.json
```

#### Testar parsing de fatura Ita√∫ (PDF):
```bash
curl -X POST "http://localhost:8081/parse_itau" \
  -H "accept: application/json" \
  -F "file=@./fatura_cartao.pdf"
```
> Resultado com as transa√ß√µes extra√≠das tamb√©m fica salvo em `parse_output.json` ao executar `python parse_pdf_direct.py` ou `.\scripts\run-parse-itau.ps1`.

#### Atualizar ap√≥s mudan√ßas no c√≥digo:
```bash
# Ap√≥s fazer push para main ou altera√ß√µes locais
docker-compose restart  # Reinicia com o c√≥digo atual
```

**Nota**: Mudan√ßas no c√≥digo Python n√£o requerem rebuild. Apenas `restart` √© suficiente. Use `--build` apenas para mudan√ßas em `requirements.txt` ou `Dockerfile`.

**Depend√™ncias fixas (sklearn/joblib)**: ap√≥s alterar `requirements.txt` para pinagem de vers√µes (por exemplo, `scikit-learn==1.6.1` e `joblib==1.4.2`), execute `docker-compose build` ou refa√ßa a imagem no ambiente de deploy para garantir que a vers√£o correta seja usada em produ√ß√£o. Valide a imagem com `pip show scikit-learn joblib` dentro do container ap√≥s o build.

---

## 1. Vis√£o Geral

### O que faz
- **Classifica Natureza do Gasto** de transa√ß√µes banc√°rias automaticamente
- **Infer√™ncia de campos derivados**: tipo (cr√©dito/d√©bito), parcelas, compartilhamento
- **Pipeline h√≠brido**: Regras ‚Üí Similaridade ‚Üí Modelo ML ‚Üí Fallback
- **API FastAPI** para integra√ß√£o com sistemas externos
- **Testes automatizados** com 173 testes cobrindo todos os componentes

### Pontos-chave
- ‚úÖ **Execu√ß√£o local** sem depend√™ncias externas obrigat√≥rias
- ‚úÖ **API REST** com documenta√ß√£o interativa
- ‚úÖ **Thresholds configur√°veis** via vari√°veis de ambiente
- ‚úÖ **Modelos sklearn** treinados com valida√ß√£o cruzada e calibra√ß√£o
- ‚úÖ **Sistema de feedback** para melhoria cont√≠nua
- ‚úÖ **Pipeline de retreino** automatizado com backup e valida√ß√£o
- ‚úÖ **Testes de diagn√≥stico** para valida√ß√£o de casos espec√≠ficos

## 2. Stack Tecnol√≥gica

### Linguagem e Runtime
- **Python 3.11**: Linguagem principal do projeto
- **Docker**: Containeriza√ß√£o para deploy e desenvolvimento
- **Docker Compose**: Orquestra√ß√£o de containers para ambiente local

### Framework Web e API
- **FastAPI 0.104+**: Framework web moderno e ass√≠ncrono para constru√ß√£o da API REST
- **Uvicorn**: Servidor ASGI de alta performance
- **Pydantic 2.0+**: Valida√ß√£o de dados e serializa√ß√£o

### Machine Learning e Processamento de Dados
- **scikit-learn 1.6.1**: Biblioteca principal para ML
  - `LogisticRegression`: Classificador linear balanceado
  - `LinearSVC`: Support Vector Classifier
  - `CalibratedClassifierCV`: Calibra√ß√£o de probabilidades
  - `TfidfVectorizer`: Vetoriza√ß√£o de texto
  - `StratifiedKFold`: Valida√ß√£o cruzada estratificada
- **pandas 1.5+**: Manipula√ß√£o e an√°lise de dados
- **numpy 1.21+**: Computa√ß√£o num√©rica
- **joblib 1.4.2**: Serializa√ß√£o de modelos ML

### Processamento de Documentos
- **pdfplumber 0.10+**: Extra√ß√£o de texto e dados de PDFs
- **PyPDF2 3.0+**: Processamento adicional de PDFs
- **openpyxl 3.0+**: Leitura de arquivos Excel
- **xlrd 2.0+**: Suporte adicional para Excel

### APIs Externas (Opcionais)
- **OpenAI API**: Fallback inteligente com GPT-4o-mini
- **Anthropic API**: Fallback alternativo com Claude-3-haiku
- **SerpAPI**: Busca de contexto sobre estabelecimentos

### Ferramentas de Desenvolvimento
- **pytest 7.0+**: Framework de testes automatizados
- **python-dotenv**: Gerenciamento de vari√°veis de ambiente
- **requests**: Cliente HTTP para APIs externas

### Infraestrutura e Deploy
- **Docker**: Containeriza√ß√£o
- **Google Cloud Run**: Plataforma de deploy serverless (opcional)
- **GCP Artifact Registry**: Registry de imagens Docker (opcional)

### Estrutura de Dados
- **CSV**: Formato principal para dados de treinamento e feedbacks
- **JSON**: Formato de comunica√ß√£o da API REST
- **PKL (joblib)**: Serializa√ß√£o de modelos treinados

## 3. Arquitetura

### Fluxo de Classifica√ß√£o
```
Transa√ß√£o ‚Üí Regras ‚Üí Similaridade (TF-IDF) ‚Üí Modelo sklearn ‚Üí Fallback IA ‚Üí "duvida"
```

**Nota**: Regras determin√≠sticas e TF-IDF podem ser desabilitados via feature flags.

### Estrutura do Projeto
```
üìÅ spend_classification/
‚îú‚îÄ‚îÄ core/           # Contratos, schemas e constantes
‚îú‚îÄ‚îÄ engines/        # Regras, similaridade, model_adapter, pipeline
‚îî‚îÄ‚îÄ tests/          # Su√≠te automatizada (173 testes)

üìÅ app/             # Servi√ßo FastAPI
‚îú‚îÄ‚îÄ main.py         # Endpoints /healthz, /v1/classify e /parse_itau
‚îú‚îÄ‚îÄ routes_feedback.py  # Endpoints de feedback e pipeline
‚îú‚îÄ‚îÄ services/       # Servi√ßos de ingest√£o e pipeline
‚îî‚îÄ‚îÄ samples/        # Payloads de exemplo

üìÅ modelos/         # Artefatos .pkl (modelos sklearn treinados)
üìÅ inputs/          # Dados de entrada (faturas, extratos)
üìÅ outputs/         # Resultados processados
üìÅ feedbacks/       # Corre√ß√µes manuais para retreinamento

üìÑ treinar_modelo.py  # Script de treinamento com valida√ß√£o cruzada
```

### Comunica√ß√£o entre Componentes
- **Pipeline** orquestra: RulesEngine ‚Üí SimilarityClassifier ‚Üí ModelAdapter ‚Üí AIFallbackEngine
- **Thresholds** configur√°veis: `SIMILARITY_THRESHOLD=0.70`, `MODEL_THRESHOLD=0.70`
- **Feature flags** controlam quais engines est√£o ativos
- **FastAPI** exp√µe endpoints que delegam para o pipeline

## 4. Classifica√ß√µes Poss√≠veis (Natureza do Gasto)

### Lista Can√¥nica de Categorias
*Gerada automaticamente das fontes do projeto: constants.py, modelos sklearn e CSVs hist√≥ricos*

#### ‚úÖ Dispon√≠vel no Modelo
- Carro (Manuten√ß√£o/ IPVA/ Seguro)
- Casamento
- Combust√≠vel/ Passagens/ Uber / Sem Parar
- Conta de g√°s
- Conta de luz
- Cuidados Pessoais (Nutricionista / Medico / Suplemento)
- Farm√°cia
- Financiamento/Condominio
- Futevolei
- Gastos com Cachorro
- Gastos com casa (outros)
- Gastos com Diarista
- Gastos com Educa√ß√£o (Ingl√™s, MBA, P√≥s)
- Gastos com mensalidades (Gympass, Spotfy, Unicef e Rappi)
- Gastos com presentes
- Gastos pessoais
- Internet & TV a cabo
- Intelig√™ncia Artificial
- Investimento
- Moradia (Financiamento/ Aluguel/ Condominio)
- Obra casa
- Planos de celular
- Restaurantes/ Bares/ Lanchonetes
- Sal√°rio
- Supermercado
- Viagens / F√©rias

#### üìä Somente no Hist√≥rico
- duvida *(categoria especial para baixa confian√ßa)*

## 5. Regras de Classifica√ß√£o

### 4.1 Regras Determin√≠sticas (Opcional)
**Status**: Desabilitado por padr√£o (`ENABLE_DETERMINISTIC_RULES=false`)

#### **tipo**: Detec√ß√£o de D√©bito
- **Regra**: Se `card` come√ßar com "CC -" ‚Üí tipo = "d√©bito" (confian√ßa: 0.95)
- **Aplica√ß√£o**: Primeira regra executada, alta prioridade

#### **comp**: Compartilhamento por Cart√£o
- **Regra**: Se `card` cont√©m "CASA" ‚Üí comp = "planilha comp" (confian√ßa: 0.90)
- **Aplica√ß√£o**: Detecta gastos compartilhados da casa

#### **parcelas**: Extra√ß√£o de Parcelamento
- **Regra**: Detectar padr√£o n/m (ex: "3/12") em descri√ß√µes
- **Aplica√ß√£o**: Preenche `no_da_parcela` e `parcelas` automaticamente
- **Exemplo**: "Compra 3/12" ‚Üí no_da_parcela=3, parcelas=12

#### **Normaliza√ß√£o Textual** (Sempre Ativa)
- **Lowercase**: Todas as descri√ß√µes convertidas para min√∫sculas
- **Limpeza**: Remo√ß√£o de caracteres especiais e espa√ßos extras
- **Acentos**: Mantidos para melhor matching com hist√≥rico
- **Remo√ß√£o de palavras gen√©ricas**: Remove palavras como "pagamento", "compra", "anuidade", "debito", "credito", "pix" para melhor precis√£o
- **Remo√ß√£o de datas**: Remove datas no formato DD/MM/YYYY ou DD/MM
- **Remo√ß√£o de parcelas**: Remove padr√µes de parcelas como "(02/03)", "(1/12)", etc.
- **Remo√ß√£o de prefixos**: Remove prefixos comuns como "Evo*", "Bkg*", "Htm*", "Ifd*", etc.
- **Limpeza de par√™nteses**: Remove par√™nteses vazios e caracteres residuais

### 4.2 Similaridade TF-IDF (Opcional)
**Status**: Desabilitado por padr√£o (`ENABLE_TFIDF_SIMILARITY=false`)
- **Fonte**: `modelo_despesas_completo.csv` (base de treinamento)
- **M√©trica**: Cosseno entre vetores TF-IDF
- **Threshold padr√£o**: 0.70 (`SIMILARITY_THRESHOLD`)
- **Comportamento**: Se score ‚â• 0.70, aceita classifica√ß√£o
- **Fallback**: Se < 0.70, passa para modelo ML

### 4.3 Classificador sklearn
- **M√©todo**: `predict_proba` para confian√ßa
- **Threshold padr√£o**: 0.70 (`MODEL_THRESHOLD`)
- **Comportamento**: Se confian√ßa ‚â• 0.70, aceita classifica√ß√£o
- **Fallback**: Se < 0.70, marca como "duvida"

### 4.4 Resultado com Baixa Confian√ßa
- **Rotulagem**: "duvida" (confian√ßa: 0.3)
- **Tratamento**: Requer feedback manual servi√ßo de melhoria
- **Justificativa**: Evita classifica√ß√µes incorretas com baixa confian√ßa

### 4.5 Fallback IA (Habilitado)
**Status**: Habilitado por padr√£o (`ENABLE_FALLBACK_AI=true`)
- **Uso**: Quando o classificador interno retorna "duvida"
- **APIs Suportadas**: OpenAI (GPT-4o-mini) e Anthropic (Claude-3-haiku)
- **Configura√ß√£o**: Requer pelo menos uma chave de API (`OPENAI_API_KEY` ou `ANTHROPIC_API_KEY`)
- **Comportamento**: 
  - Se API keys dispon√≠veis: usa IA para classificar casos de d√∫vida
  - Se API keys ausentes: retorna "duvida" com `needs_keys=true`
- **Threshold**: Confian√ßa m√≠nima de 0.5 para aceitar resultado da IA
- **Integra√ß√£o SerpAPI**: Busca automaticamente contexto sobre estabelecimentos via SerpAPI quando configurado
- **Prompt enriquecido**: Inclui informa√ß√µes de busca web no contexto para melhor classifica√ß√£o
- **Extra√ß√£o de estabelecimento**: Remove prefixos gen√©ricos e datas para buscar informa√ß√µes mais relevantes

## 6. Contrato de Entrada/Sa√≠da

### Entrada (POST /v1/classify)
```json
[
  {
    "id": "optional_id",
    "description": "Netflix Com",
    "amount": 44.90,
    "date": "2024-10-18T10:00:00",
    "card_holder": "Jo√£o",
    "card_number": "1234",
    "installments": 3,
    "installment_number": 1
  }
]
```

### Entrada (POST /parse_itau)
A requisi√ß√£o deve enviar a fatura Ita√∫ em PDF via `multipart/form-data` no campo `file`.

```bash
curl -X POST "http://localhost:8081/parse_itau" \
  -H "accept: application/json" \
  -F "file=@./fatura_cartao.pdf"
```

### Sa√≠da (POST /parse_itau)
```json
{
  "items": [
    {
      "date": "2025-06-12",
      "description": "SEPHORA CIDJARDIN 04/05",
      "amount": 83.0,
      "last4": "9826",
      "flux": "Saida"
    }
    // ...demais transa√ß√µes extra√≠das
  ],
  "stats": {
    "total_lines": 245,
    "matched": 128,
    "rejected": 15,
    "sum_abs_values": 12155.52,
    "sum_saida": 12000.33,
    "sum_entrada": 155.19,
    "by_card": {
      "9826": {
        "control_total": 6821.45,
        "calculated_total": 6821.45,
        "delta": 0.0
      }
    }
  },
  "rejects": [
    {
      "line": "SAUDE.SAO PAULO",
      "reason": "Linha n√£o reconhecida (sem data, valor ou subtotal)"
    }
    // ...linhas descartadas para auditoria
  ]
}
```

#### Scripts de apoio
- `scripts/test-parse-itau.ps1` ‚Äì Envia a fatura para `POST /parse_itau` e imprime/gera JSON de sa√≠da.
- `scripts/run-parse-itau.ps1` ‚Äì Mata processos Python antigos, sobe o servidor (`run_server.py`), aguarda `/healthz`, executa o teste acima e salva `parse_output.json`.
- `parse_pdf_direct.py` ‚Äì Executa o parser localmente (sem HTTP) usando `card_pdf_parser` e grava `parse_output.json`.

### Sa√≠da
```json
{
  "predictions": [
    {
      "label": "Gastos com mensalidades (Gympass, Spotfy, Unicef e Rappi)",
      "confidence": 0.95,
      "method_used": "rules_engine",
      "elapsed_ms": 2.5,
      "transaction_id": "optional_id",
      "needs_keys": null,
      "raw_prediction": {...}
    }
  ],
  "elapsed_ms": 15.2,
  "total_transactions": 1
}
```

### Campos de Resposta
- **label**: Categoria predita
- **confidence**: Confian√ßa da predi√ß√£o (0.0-1.0)
- **method_used**: M√©todo usado ("rules_engine", "similarity_engine", "model_adapter", "ai_fallback_openai", "ai_fallback_anthropic", "fallback", "error")
- **elapsed_ms**: Tempo de processamento em milissegundos
- **transaction_id**: ID da transa√ß√£o original (opcional)
- **needs_keys**: Indica se faltam API keys para fallback IA (opcional, apenas quando true)
- **raw_prediction**: Dados brutos da predi√ß√£o para debugging

### Campos Derivados
- **tipo**: "cr√©dito" ou "d√©bito" (inferido por regras)
- **parcelas**: Total de parcelas (extra√≠do de descri√ß√£o)
- **no_da_parcela**: Parcela atual (extra√≠do de descri√ß√£o)
- **comp**: Compartilhamento (inferido por regras)

## 7. API de Feedback

### O que √© o endpoint /v1/feedback

O endpoint `/v1/feedback` permite registrar **corre√ß√µes do usu√°rio** em transa√ß√µes classificadas para posterior incorpora√ß√£o ao modelo de treinamento. Essas corre√ß√µes s√£o essenciais para melhorar continuamente a precis√£o do sistema de classifica√ß√£o.

**Finalidade**: Coletar feedback manual para retreino dos modelos e melhoria da acur√°cia.

### Campos Aceitos

#### Campos Obrigat√≥rios
- **`transactionId`** (string): ID √∫nico da transa√ß√£o
- **`description`** (string): Descri√ß√£o da transa√ß√£o - "Aonde Gastou"
- **`amount`** (number): Valor unit√°rio da transa√ß√£o (deve ser > 0)
- **`date`** (string): Data da transa√ß√£o no formato ISO

#### Campos Principais (Opcionais)
- **`source`** (string): Tipo/fonte da transa√ß√£o (ex: "cr√©dito", "d√©bito")
- **`card`** (string): Informa√ß√µes do cart√£o
- **`modelVersion`** (string): Vers√£o do modelo usado na classifica√ß√£o
- **`createdAt`** (string): Timestamp de cria√ß√£o do feedback

#### Campos Edit√°veis (Opcionais)
- **`category`** (string): Natureza do Gasto - categoria corrigida
- **`flux`** (string): Entrada/Sa√≠da - fluxo da transa√ß√£o
- **`comp`** (string): Comp - informa√ß√£o adicional
- **`parcelas`** (number): N√∫mero total de parcelas (default: 1)
- **`numero_parcela`** (number): N√∫mero da parcela atual

### Mapeamento para CSV

Os campos s√£o mapeados para as seguintes colunas do CSV (na ordem especificada):

| Campo de Entrada | Coluna CSV | Descri√ß√£o |
|------------------|------------|-----------|
| `description` | **Aonde Gastou** | Descri√ß√£o da transa√ß√£o |
| `category` | **Natureza do Gasto** | Categoria corrigida (vazio se ausente) |
| `amount * parcelas` | **Valor Total** | Valor total calculado |
| `parcelas` | **Parcelas** | Total de parcelas (default: 1) |
| `numero_parcela` | **No da Parcela** | Parcela atual (vazio se ausente) |
| `amount` | **Valor Unit√°rio** | Valor unit√°rio da transa√ß√£o |
| `source` | **tipo** | Tipo/fonte da transa√ß√£o |
| `comp` | **Comp** | Informa√ß√£o adicional |
| `date` | **Data** | Data da transa√ß√£o |
| `card` | **cartao** | Informa√ß√µes do cart√£o |
| `transactionId` | **transactionId** | ID √∫nico da transa√ß√£o |
| `modelVersion` | **modelVersion** | Vers√£o do modelo |
| `createdAt` | **createdAt** | Timestamp (preenchido automaticamente se ausente) |
| `flux` | **flux** | Fluxo da transa√ß√£o |

### Localiza√ß√£o dos Arquivos

**Diret√≥rio**: `feedbacks/`
**Padr√£o do nome**: `feedback_YYYY-MM-DD.csv`
**Exemplo**: `feedbacks/feedback_2024-01-15.csv`

Os arquivos s√£o criados automaticamente com cabe√ßalho na primeira execu√ß√£o do dia.

### Exemplos de Uso

#### curl (Unix/Linux/macOS)

**Item √∫nico:**
```bash
curl -X POST "http://localhost:8080/v1/feedback" \
  -H "Content-Type: application/json" \
  -d '{
    "feedback": {
      "transactionId": "tx_001",
      "description": "Netflix Com",
      "amount": 44.90,
      "date": "2024-01-15T00:00:00Z",
      "source": "cr√©dito",
      "card": "Final 8073 - JOAO G B CALICE",
      "category": "Entretenimento",
      "parcelas": 1,
      "modelVersion": "v1.2.0"
    }
  }'
```

**Lote de itens:**
```bash
curl -X POST "http://localhost:8080/v1/feedback" \
  -H "Content-Type: application/json" \
  -d '{
    "feedback": [
      {
        "transactionId": "tx_001",
        "description": "Netflix Com",
        "amount": 44.90,
        "date": "2024-01-15T00:00:00Z",
        "category": "Entretenimento"
      },
      {
        "transactionId": "tx_002",
        "description": "Pao De Acucar-0061",
        "amount": 401.68,
        "date": "2024-01-15T00:00:00Z",
        "category": "Supermercado"
      }
    ]
  }'
```

#### PowerShell (Windows)

**Item √∫nico:**
```powershell
$body = @{
  feedback = @{
    transactionId = "tx_001"
    description = "Netflix Com"
    amount = 44.90
    date = "2024-01-15T00:00:00Z"
    source = "cr√©dito"
    card = "Final 8073 - JOAO G B CALICE"
    category = "Entretenimento"
    parcelas = 1
    modelVersion = "v1.2.0"
  }
} | ConvertTo-Json -Depth 3

Invoke-RestMethod -Uri "http://localhost:8080/v1/feedback" -Method POST -Body $body -ContentType "application/json"
```

**Lote de itens:**
```powershell
$body = @{
  feedback = @(
    @{
      transactionId = "tx_001"
      description = "Netflix Com"
      amount = 44.90
      date = "2024-01-15T00:00:00Z"
      category = "Entretenimento"
    },
    @{
      transactionId = "tx_002"
      description = "Pao De Acucar-0061"
      amount = 401.68
      date = "2024-01-15T00:00:00Z"
      category = "Supermercado"
    }
  )
} | ConvertTo-Json -Depth 4

Invoke-RestMethod -Uri "http://localhost:8080/v1/feedback" -Method POST -Body $body -ContentType "application/json"
```

### Resposta Esperada

**Status**: `201 Created`

```json
{
  "saved_rows": 2,
  "file_path": "feedbacks/feedback_2024-01-15.csv",
  "columns": [
    "Aonde Gastou",
    "Natureza do Gasto",
    "Valor Total",
    "Parcelas",
    "No da Parcela",
    "Valor Unit√°rio",
    "tipo",
    "Comp",
    "Data",
    "cartao",
    "transactionId",
    "modelVersion",
    "createdAt",
    "flux"
  ]
}
```

### Boas Pr√°ticas

- **Envio em lote**: Prefira enviar m√∫ltiplos feedbacks por dia em uma √∫nica requisi√ß√£o
- **Tamanho do payload**: Evite payloads gigantes (sugerimos < 5.000 itens por POST)
- **Timezone**: O arquivo usa a data do servidor (n√£o precisa especificar timezone)
- **Deduplica√ß√£o**: TransactionIds repetidos s√£o registrados novamente (comportamento intencional)
- **Concorr√™ncia**: O sistema √© thread-safe para m√∫ltiplas requisi√ß√µes simult√¢neas

### Troubleshooting

#### Erro 422 - Campos Obrigat√≥rios Ausentes
```json
{
  "detail": [
    {
      "loc": ["body", "feedback", 0, "transactionId"],
      "msg": "field required",
      "type": "missing"
    }
  ]
}
```
**Solu√ß√£o**: Verificar se todos os campos obrigat√≥rios est√£o presentes: `transactionId`, `description`, `amount`, `date`

#### Erro 422 - Amount Inv√°lido
```json
{
  "detail": [
    {
      "loc": ["body", "feedback", 0, "amount"],
      "msg": "Input should be greater than 0",
      "type": "greater_than"
    }
  ]
}
```
**Solu√ß√£o**: O campo `amount` deve ser maior que 0

#### Permiss√µes de Escrita na Pasta feedbacks/
```
ERROR: Permission denied: 'feedbacks/feedback_2024-01-15.csv'
```
**Solu√ß√£o**: Verificar permiss√µes de escrita no diret√≥rio `feedbacks/` ou criar o diret√≥rio se n√£o existir

#### Onde Ver Logs
- **Desenvolvimento local**: Logs aparecem no terminal onde o servidor est√° rodando
- **Docker**: `docker logs <container_id>`
- **Cloud Run**: Logs dispon√≠veis no Google Cloud Console
- **Swagger UI**: Documenta√ß√£o interativa dispon√≠vel em `/docs`

### Documenta√ß√£o Interativa

Para testar o endpoint interativamente, acesse:
- **Swagger UI**: http://localhost:8080/docs
- **ReDoc**: http://localhost:8080/redoc

### Pipeline de Ingest√£o e Retreino (Implementado)

O sistema agora inclui um **pipeline completo de ingest√£o e retreino** implementado e testado, com endpoints dedicados para gerenciar todo o fluxo de dados.

#### **üîÑ Endpoints do Pipeline**

| Endpoint | M√©todo | Descri√ß√£o |
|----------|--------|-----------|
| `/v1/feedback/pipeline/status` | GET | Status completo do pipeline |
| `/v1/feedback/pipeline/collect` | POST | Coleta feedbacks n√£o processados |
| `/v1/feedback/pipeline/merge` | POST | Mescla feedbacks com dataset principal |
| `/v1/feedback/pipeline/retrain` | POST | Retreina modelos com dados atualizados |
| `/v1/feedback/pipeline/run-complete` | POST | Executa pipeline completo |
| `/v1/feedback/pipeline/backup/list` | GET | Lista backups dispon√≠veis |
| `/v1/feedback/pipeline/clear-processed` | POST | Limpa arquivos processados |

#### **üìä Status do Pipeline**

```bash
# Verificar status atual
curl -X GET "http://localhost:8080/v1/feedback/pipeline/status"
```

**Resposta:**
```json
{
  "pipeline_status": "operational",
  "feedback_files": {
    "total_found": 5,
    "processed_count": 3,
    "pending_count": 2,
    "files": ["feedback_2024-01-15.csv", "feedback_2024-01-16.csv"],
    "processed_files": ["feedback_2024-01-13.csv", "feedback_2024-01-14.csv"]
  },
  "models": {
    "directory": "modelos",
    "count": 3,
    "files": {
      "modelo_natureza_do_gasto.pkl": 1703123456.789,
      "modelo_comp.pkl": 1703123456.789,
      "modelo_parcelas.pkl": 1703123456.789
    },
    "last_updated": 1703123456.789
  },
  "backups": {
    "count": 2,
    "files": ["modelo_despesas_completo.csv.backup_20240115_120000"]
  },
  "dataset_base": {
    "file": "modelo_despesas_completo.csv",
    "exists": true,
    "info": {
      "exists": true,
      "columns": 14,
      "sample_rows": 5,
      "file_size": 1024000
    }
  }
}
```

#### **üöÄ Pipeline Completo**

```bash
# Executar pipeline completo (recomendado para produ√ß√£o)
curl -X POST "http://localhost:8080/v1/feedback/pipeline/run-complete"
```

**Fluxo autom√°tico:**
1. **Coleta** feedbacks n√£o processados
2. **Mescla** com dataset principal
3. **Cria backup** autom√°tico
4. **Retreina** modelos
5. **Valida** qualidade dos resultados

#### **üîß Opera√ß√µes Individuais**

```bash
# 1. Coletar feedbacks
curl -X POST "http://localhost:8080/v1/feedback/pipeline/collect"

# 2. Mesclar com dataset
curl -X POST "http://localhost:8080/v1/feedback/pipeline/merge"

# 3. Retreinar modelos
curl -X POST "http://localhost:8080/v1/feedback/pipeline/retrain"
```

#### **üíæ Gerenciamento de Backups**

```bash
# Listar backups dispon√≠veis
curl -X GET "http://localhost:8080/v1/feedback/pipeline/backup/list"
```

**Resposta:**
```json
{
  "success": true,
  "backups": [
    {
      "file": "modelo_despesas_completo.csv.backup_20240115_120000",
      "created": 1703123456.789,
      "size": 1024000,
      "exists": true
    }
  ],
  "count": 1
}
```

#### **üîÑ Controle de Processamento**

```bash
# Limpar arquivos processados (para reprocessar)
curl -X POST "http://localhost:8080/v1/feedback/pipeline/clear-processed"
```

#### **üìà M√©tricas e Monitoramento**

O pipeline fornece m√©tricas detalhadas em cada opera√ß√£o:

- **Feedbacks coletados**: Quantidade de arquivos processados
- **Registros integrados**: Total de registros adicionados
- **Duplicatas removidas**: Estat√≠sticas de limpeza
- **Modelos atualizados**: Lista de modelos retreinados
- **Qualidade**: Resultados das valida√ß√µes
- **Tempo de execu√ß√£o**: Dura√ß√£o de cada etapa

#### **‚ö†Ô∏è Considera√ß√µes Importantes**

1. **Backup Autom√°tico**: Dataset original √© sempre preservado
2. **Controle de Duplica√ß√£o**: TransactionIds duplicados s√£o detectados
3. **Valida√ß√£o de Qualidade**: M√∫ltiplas valida√ß√µes em cada etapa
4. **Timeout**: Retreino tem limite de 10 minutos
5. **Idempot√™ncia**: Opera√ß√µes podem ser executadas m√∫ltiplas vezes
6. **Rollback**: Sistema pode ser restaurado em caso de erro

#### **üéØ Casos de Uso**

- **Integra√ß√£o Di√°ria**: Processar feedbacks acumulados diariamente
- **Retreino Semanal**: Atualizar modelos semanalmente
- **Deploy**: Preparar sistema para produ√ß√£o
- **Manuten√ß√£o**: Opera√ß√µes de manuten√ß√£o programada
- **Desenvolvimento**: Testes e desenvolvimento com dados reais

#### **üîç Troubleshooting do Pipeline**

| Problema | Solu√ß√£o |
|----------|---------|
| **Nenhum feedback encontrado** | Verificar se arquivos existem em `feedbacks/` |
| **Erro na mesclagem** | Verificar se dataset base existe e √© v√°lido |
| **Timeout no retreino** | Verificar tamanho dos dados e recursos do sistema |
| **Modelos n√£o atualizados** | Verificar logs do `treinar_modelo.py` |
| **Backup n√£o encontrado** | Verificar permiss√µes de escrita no diret√≥rio |

## 8. Configura√ß√£o para Containers

### Vari√°veis de Ambiente Suportadas

A aplica√ß√£o est√° preparada para rodar 100% em container com as seguintes vari√°veis:

| Vari√°vel | Default | Descri√ß√£o |
|----------|---------|-----------|
| `PORT` | `8080` | Porta do servidor FastAPI |
| `MODEL_DIR` | `./modelos` | Diret√≥rio dos modelos .pkl |
| `SIMILARITY_THRESHOLD` | `0.70` | Threshold para Similarity Engine |
| `MODEL_THRESHOLD` | `0.70` | Threshold para Model Adapter |
| `ENABLE_FALLBACK_AI` | `true` | Habilitar fallback com IA (padr√£o: habilitado) |
| `ENABLE_DETERMINISTIC_RULES` | `false` | Habilitar regras determin√≠sticas |
| `ENABLE_TFIDF_SIMILARITY` | `false` | Habilitar similaridade TF-IDF |
| `USE_PIPELINE_MODEL` | `true` | Usar modelo pipeline completo |
| `TRAINING_DATA_FILE` | `modelo_despesas_completo.csv` | Arquivo CSV para treinamento |

### Caracter√≠sticas para Container

- ‚úÖ **Health Check**: `GET /healthz` retorna `{"status":"ok"}`
- ‚úÖ **Shutdown Gracioso**: Responde a SIGTERM sem pend√™ncias
- ‚úÖ **Degrada√ß√£o Graciosa**: Funciona sem CSVs hist√≥ricos
- ‚úÖ **Modelos Flex√≠veis**: Carrega .pkl via MODEL_DIR
- ‚úÖ **Porta Configur√°vel**: Usa vari√°vel PORT (padr√£o 8080)

### Exemplo de Dockerfile

```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

# Copiar modelos se existirem
COPY modelos/ ./modelos/

# Expor porta configur√°vel
EXPOSE 8080

# Usar vari√°vel PORT
ENV PORT=8080
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8080"]
```

### Arquivos de Exemplo Inclu√≠dos

- **`Dockerfile.example`**: Dockerfile completo com health check
- **`docker-compose.example.yml`**: Configura√ß√£o para desenvolvimento local
- **`deploy-cloud-run.example.sh`**: Script de deploy para Google Cloud Run
- **`validate-container.sh`**: Comandos de valida√ß√£o para testes

## 9. Rodar com Docker (Local)

### Pr√©-requisitos
- Docker instalado
- Arquivo `.env` configurado (opcional)

### Build e Execu√ß√£o

#### 1. Build da Imagem
```bash
# Build da imagem Docker
docker build -t ml-service:local .
```

#### 2. Executar Container
```bash
# Executar com arquivo .env (recomendado)
docker run --rm -p 8081:8080 --env-file .env ml-service:local

# Ou executar com vari√°veis inline
docker run --rm -p 8080:8080 \
  -e PORT=8080 \
  -e ENABLE_FALLBACK_AI=true \
  -e SIMILARITY_THRESHOLD=0.70 \
  -e MODEL_THRESHOLD=0.70 \
  -e MODEL_DIR=/models \
  ml-service:local
```

#### 3. Testar Aplica√ß√£o
```bash
# Health check
curl http://localhost:8081/healthz

# Classificar transa√ß√£o √∫nica
curl -X POST "http://localhost:8081/v1/classify" \
  -H "Content-Type: application/json" \
  -d '[
    {
      "description": "Netflix Com",
      "amount": 44.90,
      "date": "2024-01-01"
    }
  ]'
```

### Caracter√≠sticas do Container

- ‚úÖ **Base**: `python:3.11-slim` (imagem otimizada)
- ‚úÖ **Usu√°rio n√£o-root**: Executa como `appuser` para seguran√ßa
- ‚úÖ **Health Check**: Verifica√ß√£o autom√°tica de sa√∫de
- ‚úÖ **Modelos**: Copiados para `/models` (paridade com Cloud Run)
- ‚úÖ **Vari√°veis**: Configura√ß√µes padr√£o otimizadas para container
- ‚úÖ **Worker √∫nico**: Configurado para 1 worker (ideal para containers)

## 10. Comandos Make e Scripts Auxiliares

### Comandos Make Dispon√≠veis

| Comando | Descri√ß√£o | Equivalente Windows |
|---------|-----------|-------------------|
| `make run-api` | Inicia API FastAPI | `uvicorn app.main:app --reload --port 8080` |
| `make test` | Executa testes pytest | `pytest -q` |
| `make docker-build` | Build da imagem Docker | `docker build -t ml-service:local .` |
| `make docker-run` | Executa container Docker | `docker run --rm -p 8081:8080 --env-file .env ml-service:local` |
| `make docker-stop` | Para container Docker | `docker stop ml-service:local` |

### Scripts de Teste CLI

#### Unix/Linux/macOS
```bash
# Testar transa√ß√£o √∫nica
./scripts/test-single.sh

# Testar lote de transa√ß√µes
./scripts/test-batch.sh
```

#### Windows (CMD)
```cmd
REM Testar transa√ß√£o √∫nica
scripts\test-single.bat

REM Testar lote de transa√ß√µes
scripts\test-batch.bat
```

#### Windows (PowerShell)
```powershell
# Testar transa√ß√£o √∫nica
.\scripts\test-single.ps1

# Testar lote de transa√ß√µes
.\scripts\test-batch.ps1
```

### Exemplos de Uso

#### 1. Desenvolvimento Local
```bash
# Iniciar API
make run-api

# Em outro terminal, testar
./scripts/test-single.sh
```

#### 2. Testes com Docker
```bash
# Build e execu√ß√£o
make docker-build
make docker-run

# Em outro terminal, testar
./scripts/test-batch.sh
```

#### 3. Windows PowerShell
```powershell
# Iniciar API
uvicorn app.main:app --reload --port 8080

# Em outro terminal, testar
.\scripts\test-single.ps1
```

## 11. Smoke Test do Container (Local)

### O que √© o Smoke Test

O smoke test √© um teste automatizado que valida todo o ciclo de vida do container Docker:
1. **Build** da imagem
2. **Execu√ß√£o** em background
3. **Health check** com polling
4. **Classifica√ß√£o** de transa√ß√£o
5. **Valida√ß√£o** de campos obrigat√≥rios
6. **Limpeza** autom√°tica do container

### Como Executar

#### Unix/Linux/macOS
```bash
# Tornar script execut√°vel
chmod +x scripts/docker-smoke.sh

# Executar smoke test
./scripts/docker-smoke.sh
```

#### Windows (CMD)
```cmd
REM Executar smoke test
scripts\docker-smoke.bat
```

#### Windows (PowerShell)
```powershell
# Executar smoke test
.\scripts\docker-smoke.ps1
```

### Sa√≠da Esperada (Sucesso)

```
üöÄ Iniciando smoke test do container Docker
================================================

üì¶ Fazendo build da imagem...
‚úÖ Build conclu√≠do

üöÄ Executando container em background...
‚úÖ Container iniciado

üè• Aguardando health check...
URL: http://localhost:8081/healthz
Timeout: 30s
‚úÖ Health check OK (5s)

üéØ Testando classifica√ß√£o...
üìÑ Arquivo: app/samples/tx_single.json
üì§ Enviando requisi√ß√£o...
üìä C√≥digo HTTP: 200
‚úÖ HTTP 200 OK

üîç Verificando campos obrigat√≥rios...
üìä Resposta da API:
{
  "predictions": [
    {
      "label": "Gastos com mensalidades (Gympass, Spotfy, Unicef e Rappi)",
      "confidence": 0.95,
      "method_used": "model_adapter",
      "elapsed_ms": 5.2,
      "transaction_id": null,
      "needs_keys": null
    }
  ],
  "elapsed_ms": 15.2,
  "total_transactions": 1
}

üîç Campos verificados:
  Label: Gastos com mensalidades (Gympass, Spotfy, Unicef e Rappi)
  Confidence: 0.95
  Method: model_adapter
‚úÖ Label encontrado: Gastos com mensalidades (Gympass, Spotfy, Unicef e Rappi)
‚úÖ Confidence v√°lido: 0.95

üéâ Smoke test conclu√≠do com sucesso!
================================================
‚úÖ Build da imagem: OK
‚úÖ Container executando: OK
‚úÖ Health check: OK
‚úÖ Classifica√ß√£o: OK
‚úÖ Campos obrigat√≥rios: OK

üí° Container ser√° parado automaticamente
```

### Crit√©rios de Sucesso

- ‚úÖ **Status de sa√≠da**: 0 (sucesso) ou ‚â†0 (erro)
- ‚úÖ **Build**: Imagem constru√≠da sem erros
- ‚úÖ **Container**: Executando em background na porta 8081
- ‚úÖ **Health check**: Responde `/healthz` em at√© 30s
- ‚úÖ **Classifica√ß√£o**: POST `/v1/classify` retorna HTTP 200
- ‚úÖ **Campos obrigat√≥rios**: `predictions[0].label` presente
- ‚úÖ **Limpeza**: Container parado automaticamente

### Troubleshooting

#### Timeout no Health Check
```
‚ùå Timeout no health check ap√≥s 30s
üìã Logs do container:
```
**Solu√ß√£o**: Verificar se Docker est√° rodando e porta 8081 est√° livre

#### Erro no Build
```
‚ùå Erro no build da imagem
```
**Solu√ß√£o**: Verificar se Dockerfile existe e depend√™ncias est√£o corretas

#### Campos N√£o Encontrados
```
‚ùå Label n√£o encontrado
```
**Solu√ß√£o**: Verificar se modelos est√£o presentes no container

## 12. Deploy no GCP Cloud Run

### Conven√ß√£o de Imagem e Tags

#### Registry GCP
```
southamerica-east1-docker.pkg.dev/<SEU_PROJECT_ID>/ml-repo/ml-service:<tag>
```

#### Tags Recomendadas
- **Vers√µes**: `v1`, `v2`, `v3`, etc.
- **Testes**: `latest` (apenas para desenvolvimento)
- **Ambientes**: `dev`, `staging`, `prod` (opcional)

#### Exemplos de Tags
```bash
# Vers√£o espec√≠fica
southamerica-east1-docker.pkg.dev/my-project/ml-repo/ml-service:v1

# √öltima vers√£o
southamerica-east1-docker.pkg.dev/my-project/ml-repo/ml-service:latest

# Ambiente espec√≠fico
southamerica-east1-docker.pkg.dev/my-project/ml-repo/ml-service:prod-v1
```

### Caminhos de Build

#### 1. Build Local (Debug)
```bash
# Build local para testes
docker build -t ml-service:local .

# Testar localmente
docker run --rm -p 8080:8080 ml-service:local

# Smoke test
./scripts/docker-smoke.sh
```

#### 2. Build Remoto (Produ√ß√£o)
```bash
# Configurar projeto
gcloud config set project <SEU_PROJECT_ID>

# Configurar Docker para GCP
gcloud auth configure-docker southamerica-east1-docker.pkg.dev

# Build e push em uma opera√ß√£o
gcloud builds submit --tag southamerica-east1-docker.pkg.dev/<SEU_PROJECT_ID>/ml-repo/ml-service:v1

# Deploy no Cloud Run
gcloud run deploy ml-service \
  --image southamerica-east1-docker.pkg.dev/<SEU_PROJECT_ID>/ml-repo/ml-service:v1 \
  --region southamerica-east1 \
  --platform managed \
  --allow-unauthenticated \
  --port 8080 \
  --memory 1Gi \
  --cpu 1 \
  --max-instances 10 \
  --set-env-vars "PORT=8080,MODEL_DIR=/models,SIMILARITY_THRESHOLD=0.70,MODEL_THRESHOLD=0.70,ENABLE_FALLBACK_AI=true"
```

### Checklist Cloud Run Ready

- ‚úÖ **App escuta PORT**: Configurado para usar vari√°vel `PORT` (default 8080)
- ‚úÖ **Porta padr√£o 8080**: Definida no Dockerfile e vari√°veis de ambiente
- ‚úÖ **Sem volumes obrigat√≥rios**: Todos os artefatos inclu√≠dos na imagem
- ‚úÖ **Modelos inclu√≠dos**: Copiados para `/models` no container
- ‚úÖ **Health check dispon√≠vel**: Endpoint `/healthz` implementado
- ‚úÖ **Vari√°veis de ambiente**: Definidas no deploy do Cloud Run
- ‚úÖ **Usu√°rio n√£o-root**: Execu√ß√£o segura como `appuser`
- ‚úÖ **Worker √∫nico**: Configurado para 1 worker (ideal para containers)
- ‚úÖ **Shutdown gracioso**: Responde a SIGTERM sem pend√™ncias

### Script de Deploy Completo

```bash
#!/bin/bash
# Script de deploy para GCP Cloud Run

set -e

# Configura√ß√µes
PROJECT_ID="<SEU_PROJECT_ID>"
SERVICE_NAME="ml-service"
REGION="southamerica-east1"
IMAGE_NAME="southamerica-east1-docker.pkg.dev/${PROJECT_ID}/ml-repo/ml-service"
TAG="v1"

echo "üöÄ Deploy para GCP Cloud Run"
echo "Projeto: $PROJECT_ID"
echo "Servi√ßo: $SERVICE_NAME"
echo "Regi√£o: $REGION"
echo "Imagem: $IMAGE_NAME:$TAG"

# 1. Configurar projeto
echo "üìã Configurando projeto..."
gcloud config set project $PROJECT_ID

# 2. Configurar Docker
echo "üê≥ Configurando Docker para GCP..."
gcloud auth configure-docker southamerica-east1-docker.pkg.dev

# 3. Build e push
echo "üì¶ Fazendo build e push..."
gcloud builds submit --tag $IMAGE_NAME:$TAG

# 4. Deploy no Cloud Run
echo "üåê Fazendo deploy no Cloud Run..."
gcloud run deploy $SERVICE_NAME \
  --image $IMAGE_NAME:$TAG \
  --region $REGION \
  --platform managed \
  --allow-unauthenticated \
  --port 8080 \
  --memory 1Gi \
  --cpu 1 \
  --max-instances 10 \
  --set-env-vars "PORT=8080,MODEL_DIR=/models,SIMILARITY_THRESHOLD=0.70,MODEL_THRESHOLD=0.70,ENABLE_FALLBACK_AI=true"

# 5. Obter URL do servi√ßo
echo "üîó URL do servi√ßo:"
gcloud run services describe $SERVICE_NAME --region $REGION --format 'value(status.url)'

echo "‚úÖ Deploy conclu√≠do!"
```

## 13. Docker Compose (Opcional)

### Quando Usar Docker Compose

O docker-compose √© **opcional** e destinado apenas para **desenvolvimento local**. Para produ√ß√£o no GCP Cloud Run, use os comandos de deploy direto.

#### Vantagens do Docker Compose
- ‚úÖ **Desenvolvimento r√°pido**: `docker compose up` sobe tudo
- ‚úÖ **Hot-reload**: Mudan√ßas no c√≥digo refletem automaticamente
- ‚úÖ **Configura√ß√£o centralizada**: Vari√°veis em `.env`
- ‚úÖ **Debugging facilitado**: Logs centralizados

#### Limita√ß√µes e Trade-offs
- ‚ùå **N√£o compat√≠vel com Cloud Run**: Cloud Run n√£o usa volumes
- ‚ùå **Apenas para desenvolvimento**: N√£o deve ser usado em produ√ß√£o
- ‚ùå **Depend√™ncia local**: Requer arquivos locais para hot-reload

### Configura√ß√£o

#### Arquivos de Configura√ß√£o
- **`docker-compose.yml`**: Configura√ß√£o base (compat√≠vel com Cloud Run)
- **`docker-compose.override.yml`**: Configura√ß√£o para desenvolvimento (volumes e hot-reload)

#### Estrutura dos Arquivos
```yaml
# docker-compose.yml (base)
services:
  api:
    build: .
    ports:
      - "8081:8080"
    env_file:
      - .env
    # Sem volumes - compat√≠vel com Cloud Run

# docker-compose.override.yml (desenvolvimento)
services:
  api:
    volumes:
      - ./app:/app/app:ro  # Hot-reload
      - ./modelos:/models:ro  # Modelos locais
    command: ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8080", "--reload"]
```

### Como Usar

#### Desenvolvimento Local
```bash
# Subir com hot-reload (usa override)
docker compose up

# Subir em background
docker compose up -d

# Ver logs
docker compose logs -f api

# Parar
docker compose down
```

#### Produ√ß√£o (sem override)
```bash
# Subir sem volumes (simula Cloud Run)
docker compose -f docker-compose.yml up

# Ou usar docker run diretamente
docker run --rm -p 8081:8080 --env-file .env ml-service:local
```

### Testes com Docker Compose

#### Health Check
```bash
# Aguardar inicializa√ß√£o e testar
sleep 10
curl http://localhost:8081/healthz
```

#### Classifica√ß√£o
```bash
# Testar classifica√ß√£o
curl -X POST "http://localhost:8081/v1/classify" \
  -H "Content-Type: application/json" \
  -d '[
    {
      "description": "Netflix Com",
      "amount": 44.90,
      "date": "2024-01-01"
    }
  ]'
```

### ‚ö†Ô∏è Importante: Cloud Run vs Docker Compose

| Aspecto | Docker Compose (Dev) | Cloud Run (Prod) |
|---------|---------------------|------------------|
| **Volumes** | ‚úÖ Usa volumes locais | ‚ùå Sem volumes |
| **Hot-reload** | ‚úÖ Suportado | ‚ùå N√£o suportado |
| **Arquivos locais** | ‚úÖ Monta do host | ‚ùå Inclu√≠dos na imagem |
| **Configura√ß√£o** | ‚úÖ docker-compose.yml | ‚úÖ gcloud run deploy |
| **Escalabilidade** | ‚ùå Single instance | ‚úÖ Auto-scaling |

### Troubleshooting

#### Erro de Volume
```
ERROR: for api  Cannot start service api: error while creating mount source path
```
**Solu√ß√£o**: Verificar se diret√≥rios `app/` e `modelos/` existem

#### Porta em Uso
```
ERROR: bind: address already in use
```
**Solu√ß√£o**: Parar outros servi√ßos na porta 8080 ou usar porta diferente

#### Hot-reload N√£o Funciona
```
WARNING: Watchfiles detected changes in 'app/main.py' but reload is not enabled
```
**Solu√ß√£o**: Verificar se `docker-compose.override.yml` est√° sendo usado

## 14. Como Rodar Localmente

### Pr√©-requisitos
- Python 3.8+
- Ambiente virtual (recomendado)

### Passo a Passo

#### 1. Configurar Ambiente
```bash
# Criar ambiente virtual
python -m venv venv

# Ativar ambiente
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Instalar depend√™ncias
pip install -r requirements.txt
```

#### 2. Configurar Vari√°veis (.env)
```bash
# Copiar arquivo de exemplo (na raiz do projeto)
cp .env.example .env

# Editar conforme necess√°rio
# As vari√°veis principais s√£o:

# Thresholds de classifica√ß√£o
SIMILARITY_THRESHOLD=0.4
MODEL_THRESHOLD=0.70

# Configura√ß√µes do container
MODEL_DIR=./modelos
PORT=8080

# Feature flags (padr√£o: AI Fallback habilitado)
ENABLE_FALLBACK_AI=true
ENABLE_DETERMINISTIC_RULES=false
ENABLE_TFIDF_SIMILARITY=false
USE_PIPELINE_MODEL=true

# Arquivo de dados para treinamento
TRAINING_DATA_FILE=modelo_despesas_completo.csv

# API Keys para Fallback IA (opcional)
# Configure para usar AI Fallback e SerpAPI
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
SERPAPI_API_KEY=your_serpapi_key_here  # Recomendado para melhor classifica√ß√£o
```

#### 3. Preparar Dados e Modelos
```bash
# Garantir presen√ßa do arquivo de treinamento
# Por padr√£o usa modelo_despesas_completo.csv
# Pode ser alterado via TRAINING_DATA_FILE no .env

# Treinar modelos (usa arquivo configurado em TRAINING_DATA_FILE)
# O script executa valida√ß√£o cruzada, calibra√ß√£o e sele√ß√£o autom√°tica do melhor modelo
python treinar_modelo.py

# O script gera os seguintes arquivos em modelos/:
# - modelo_natureza_do_gasto.pkl (pipeline completo)
# - vectorizer.pkl (componente TF-IDF)
# - classifier.pkl (componente classificador)
# - modelo_comp.pkl (compartilhamento)
# - modelo_parcelas.pkl (total de parcelas)
# - modelo_no_da_parcela.pkl (n√∫mero da parcela)
# - modelo_tipo.pkl (tipo cr√©dito/d√©bito)

# Verificar se os modelos foram gerados corretamente
ls -la modelos/*.pkl
```

#### 4. Iniciar API
```bash
# Op√ß√£o 1: Usando o script de conveni√™ncia (RECOMENDADO)
python run_server.py

# Op√ß√£o 2: Usando uvicorn diretamente com PORT configur√°vel
uvicorn app.main:app --reload --port ${PORT:-8080}

# Op√ß√£o 3: Usando Python com path configurado
python -c "import sys; sys.path.insert(0, '.'); import uvicorn; from app.main import app; uvicorn.run(app, host='127.0.0.1', port=int(os.getenv('PORT', '8080')))"
```

### Endpoints Dispon√≠veis

#### GET /healthz
```bash
curl http://127.0.0.1:8080/healthz
```
**Resposta**: `{"status":"ok"}`

#### POST /v1/classify
```bash
# Transa√ß√£o √∫nica
curl -X POST "http://127.0.0.1:8080/v1/classify" \
  -H "Content-Type: application/json" \
  -d @app/samples/tx_single.json

# Lote de transa√ß√µes
curl -X POST "http://127.0.0.1:8080/v1/classify" \
  -H "Content-Type: application/json" \
  -d @app/samples/tx_batch.json
```

### Payloads de Exemplo
- **`app/samples/tx_single.json`**: Transa√ß√£o √∫nica
- **`app/samples/tx_batch.json`**: 3 transa√ß√µes (regra, similaridade, modelo)

## 15. Como Testar

### Testes Autom√°ticos (pytest)
```bash
# Su√≠te completa
python -m pytest spend_classification/tests -q

# Testes espec√≠ficos
python -m pytest spend_classification/tests/test_rules.py -v
python -m pytest spend_classification/tests/test_similarity.py -v
python -m pytest spend_classification/tests/test_model_adapter.py -v
python -m pytest spend_classification/tests/test_pipeline.py -v
python -m pytest spend_classification/tests/test_e2e_pipeline.py -v
python -m pytest spend_classification/tests/test_api.py -v
```

### Testes da API (Script de Conveni√™ncia)
```bash
# Testar API completa (health + classifica√ß√£o)
python test_api.py

# Iniciar servidor
python run_server.py
```

### Testes Manuais (curl/PowerShell)

#### Windows PowerShell
```powershell
# Health check
Invoke-WebRequest -Uri "http://127.0.0.1:8080/healthz" -Method GET

# Classifica√ß√£o
$body = Get-Content "app\samples\tx_single.json" -Raw
Invoke-WebRequest -Uri "http://127.0.0.1:8080/v1/classify" -Method POST -Body $body -ContentType "application/json"
```

#### Linux/Mac
```bash
# Health check
curl http://127.0.0.1:8080/healthz

# Classifica√ß√£o
curl -X POST "http://127.0.0.1:8080/v1/classify" \
  -H "Content-Type: application/json" \
  -d @app/samples/tx_single.json
```

### Script de Teste Automatizado
```bash
# Executar script de teste
python test_samples.py
```

### Crit√©rios de Aceite
- ‚úÖ **predictions**: Lista preenchida
- ‚úÖ **confidence**: Valor entre 0.0 e 1.0
- ‚úÖ **elapsed_ms**: Tempo > 0
- ‚úÖ **method_used**: "rules_engine", "similarity_engine" ou "model_adapter"
- ‚úÖ **label**: Categoria v√°lida ou "duvida"

## 16. Dados e Modelos

### Arquivos .pkl Necess√°rios
```
modelos/
‚îú‚îÄ‚îÄ modelo_natureza_do_gasto.pkl    # Modelo principal (pipeline completo)
‚îú‚îÄ‚îÄ vectorizer.pkl                  # Vectorizer TF-IDF (componente separado)
‚îú‚îÄ‚îÄ classifier.pkl                  # Classificador (componente separado)
‚îú‚îÄ‚îÄ modelo_comp.pkl                 # Compartilhamento
‚îú‚îÄ‚îÄ modelo_parcelas.pkl             # Total de parcelas
‚îú‚îÄ‚îÄ modelo_no_da_parcela.pkl        # N√∫mero da parcela
‚îî‚îÄ‚îÄ modelo_tipo.pkl                 # Tipo (cr√©dito/d√©bito)
```

### Compatibilidade sklearn/joblib
- **Vers√£o sklearn**: Compat√≠vel com modelos treinados
- **Joblib**: Usado para serializa√ß√£o/deserializa√ß√£o
- **Alinhamento**: Garantir compatibilidade de vers√µes

### CSVs de Treinamento e Similaridade
- **Fonte**: `modelo_despesas_completo.csv` (configur√°vel via `TRAINING_DATA_FILE`)
- **Comportamento**: Degrada graciosamente se ausente
- **Fallback**: SimilarityClassifier retorna None se arquivo n√£o encontrado
- **Treinamento**: Script `treinar_modelo.py` usa arquivo configurado

## 16.1. Script de Treinamento (`treinar_modelo.py`)

### Vis√£o Geral

O script `treinar_modelo.py` √© respons√°vel por treinar todos os modelos de classifica√ß√£o usados pelo sistema. Ele implementa um pipeline completo de Machine Learning com valida√ß√£o cruzada, calibra√ß√£o e sele√ß√£o autom√°tica do melhor modelo.

### Como Usar

```bash
# Treinar modelos com arquivo padr√£o (modelo_despesas_completo.csv)
python treinar_modelo.py

# Ou especificar arquivo customizado via vari√°vel de ambiente
export TRAINING_DATA_FILE=meu_dataset.csv
python treinar_modelo.py
```

### Funcionalidades Principais

#### 1. **Limpeza e Normaliza√ß√£o de Texto**
- **Remo√ß√£o de datas**: Remove padr√µes de data (DD/MM/YYYY, DD-MM-YYYY)
- **Remo√ß√£o de palavras gen√©ricas**: Remove termos pouco discriminativos como "pagamento", "compra", "anuidade", "debito", "credito", "pix", "cartao"
- **Normaliza√ß√£o de espa√ßos**: Remove espa√ßos extras e normaliza o texto
- **Preserva√ß√£o de termos importantes**: Mant√©m nomes de estabelecimentos e termos espec√≠ficos que ajudam na classifica√ß√£o

#### 2. **Valida√ß√£o Cruzada Estratificada**
- **M√©todo**: StratifiedKFold com 5 folds
- **Objetivo**: Garantir que cada fold tenha distribui√ß√£o proporcional de classes
- **M√©tricas calculadas**: F1-macro, Brier score, AUC por classe
- **Sele√ß√£o de modelo**: Escolhe o melhor modelo baseado no F1-macro m√©dio na valida√ß√£o cruzada

#### 3. **Calibra√ß√£o de Probabilidades**
- **Modelos calibrados**: 
  - `LogisticRegression` com class_weight="balanced"
  - `CalibratedClassifierCV` com `LinearSVC` (m√©todo sigmoid, 3 folds)
- **Objetivo**: Garantir que as probabilidades preditas sejam calibradas e confi√°veis
- **M√©tricas**: Brier score (quanto menor, melhor) e AUC por classe

#### 4. **Balanceamento de Classes**
- **Oversampling leve**: Aumenta classes minorit√°rias at√© 70% do tamanho da classe maior (`min_frac=0.7`)
- **Aplica√ß√£o**: Apenas no conjunto de treino (n√£o afeta valida√ß√£o/teste)
- **Objetivo**: Melhorar performance em classes desbalanceadas sem overfitting excessivo

#### 5. **Remo√ß√£o de Classes Raras**
- **Crit√©rio**: Remove classes com menos de 2 exemplos
- **Justificativa**: Classes muito raras n√£o podem ser aprendidas adequadamente
- **Aviso**: Sistema imprime warning listando classes removidas

#### 6. **Modelos Treinados**

O script treina 5 modelos auxiliares e 1 modelo principal:

**Modelos Auxiliares:**
- `modelo_comp.pkl`: Compartilhamento (usa informa√ß√£o do cart√£o)
- `modelo_parcelas.pkl`: Total de parcelas
- `modelo_no_da_parcela.pkl`: N√∫mero da parcela atual
- `modelo_tipo.pkl`: Tipo (cr√©dito/d√©bito)

**Modelo Principal:**
- `modelo_natureza_do_gasto.pkl`: Pipeline completo (TF-IDF + Classificador)
- `vectorizer.pkl`: Vectorizer TF-IDF (salvo separadamente)
- `classifier.pkl`: Classificador (salvo separadamente)

#### 7. **Testes de Diagn√≥stico**

Ap√≥s o treinamento, o script executa testes de diagn√≥stico em casos espec√≠ficos:

```python
test_cases = [
    ("Hb - Imares (04/04)", "Carro (Manuten√ß√£o/ IPVA/ Seguro)"),
    ("Raiadrogasilsa", "Farm√°cia"),
    ("Ifd*Drogaria Penamar L", "Farm√°cia"),
    ("CREDITO DE SALARIO CNPJ 007526557000100", "Sal√°rio"),
]
```

Para cada caso, o script mostra:
- Texto original
- Texto limpo ap√≥s normaliza√ß√£o
- Categoria predita
- Confian√ßa da predi√ß√£o
- Categoria esperada
- Se houve match

#### 8. **M√©tricas e Relat√≥rios**

O script gera relat√≥rios detalhados:

- **Classification Report**: Precision, recall, F1-score por classe
- **Matriz de Confus√£o**: Para classes destacadas (ex: "Restaurante", "Gastos Pessoais")
- **Brier Score**: Medida de calibra√ß√£o de probabilidades (quanto menor, melhor)
- **AUC por Classe**: √Årea sob a curva ROC para cada classe (One-vs-Rest)
- **F1-macro**: M√©dia harm√¥nica de precision e recall (macro-averaged)

### Exemplo de Sa√≠da

```
[INFO] Treinando modelo principal com valida√ß√£o estratificada e calibra√ß√£o...
[WARN] Removendo classes raras com apenas 1 exemplo: ['Categoria Rara']

Distribui√ß√£o antes do oversampling: Counter({'Supermercado': 150, 'Restaurante': 80, ...})
Distribui√ß√£o ap√≥s oversampling leve: Counter({'Supermercado': 150, 'Restaurante': 105, ...})

[INFO] Validando modelo LogisticRegression (balanced) com StratifiedKFold...
[CV] LogisticRegression (balanced) - Fold 1/5: F1-macro=0.8523, Brier=0.1234
[CV] LogisticRegression (balanced) - Fold 2/5: F1-macro=0.8456, Brier=0.1256
...

[RESULTADOS - HOLD-OUT] LogisticRegression (balanced)
              precision    recall  f1-score   support
...
Brier score (quanto menor melhor): 0.1234
AUC por classe:
  - Supermercado: 0.9876
  - Restaurante: 0.9543
  ...

[OK] Melhor modelo: Calibrated LinearSVC (balanced) | F1-macro=0.8634 | Brier=0.1189

[TESTE] Verificando predi√ß√µes para casos espec√≠ficos:
  Input: Hb - Imares (04/04)
  Cleaned: hb imares
  Predicted: Carro (Manuten√ß√£o/ IPVA/ Seguro)
  Confidence: 0.892
  Expected: Carro (Manuten√ß√£o/ IPVA/ Seguro)
  Match: True
```

### Configura√ß√£o via Vari√°veis de Ambiente

```bash
# Arquivo de dados para treinamento
TRAINING_DATA_FILE=modelo_despesas_completo.csv
```

### Integra√ß√£o com Pipeline de Retreino

O script `treinar_modelo.py` √© automaticamente chamado pelo pipeline de retreino quando voc√™ executa:

```bash
# Via API
curl -X POST "http://localhost:8080/v1/feedback/pipeline/retrain"

# Ou pipeline completo
curl -X POST "http://localhost:8080/v1/feedback/pipeline/run-complete"
```

O pipeline:
1. Coleta feedbacks n√£o processados
2. Mescla com dataset principal
3. Cria backup autom√°tico
4. Executa `treinar_modelo.py` com o dataset atualizado
5. Valida qualidade dos novos modelos
6. Retorna m√©tricas de sucesso

### Boas Pr√°ticas

- **Backup antes de retreinar**: O pipeline cria backup autom√°tico, mas √© recomendado fazer backup manual tamb√©m
- **Valida√ß√£o ap√≥s treinamento**: Sempre valide os modelos com dados de teste antes de usar em produ√ß√£o
- **Monitoramento de m√©tricas**: Compare F1-macro e Brier score entre vers√µes para detectar regress√µes
- **Testes de diagn√≥stico**: Verifique se os casos de teste espec√≠ficos continuam funcionando corretamente
- **Compatibilidade de vers√µes**: Garanta que sklearn/joblib sejam compat√≠veis entre treinamento e produ√ß√£o

## 17. Desempenho e Observabilidade

### Boas Pr√°ticas
- **Vetoriza√ß√£o em lote**: Processar m√∫ltiplas transa√ß√µes simultaneamente
- **Carregamento √∫nico**: Modelos carregados uma vez na inicializa√ß√£o
- **Medi√ß√£o de tempo**: `elapsed_ms` para cada transa√ß√£o e lote total

### Dicas de Tuning
- **Thresholds**: Ajustar `SIMILARITY_THRESHOLD` e `MODEL_THRESHOLD`
- **Corpus TF-IDF**: Expandir `modelo_despesas_completo.csv` para melhor similaridade
- **Limpeza de texto**: Refinar normaliza√ß√£o para melhor matching

### Logs Sugeridos
- **Campos √∫teis**: transaction_id, method_used, confidence, elapsed_ms
- **N√≠veis**: INFO para opera√ß√µes normais, WARNING para baixa confian√ßa
- **Rota√ß√£o**: Configurar rota√ß√£o de logs para evitar crescimento excessivo

## 18. Troubleshooting

### Erros Comuns

#### Arquivo de Modelo Ausente
```
ERROR: Arquivo vectorizer.pkl n√£o encontrado em modelos/vectorizer.pkl
```
**Solu√ß√£o**: Executar `python treinar_modelo.py` para gerar modelos

#### CSV Ausente/Inv√°lido
```
WARNING: Arquivo modelo_despesas_completo.csv n√£o encontrado
```
**Solu√ß√£o**: SimilarityClassifier funciona sem arquivo (retorna None). Verifique `TRAINING_DATA_FILE` no .env

#### Thresholds Mal Configurados
```
WARNING: Confian√ßa insuficiente (0.45) para transa√ß√£o
```
**Solu√ß√£o**: Ajustar `SIMILARITY_THRESHOLD` ou `MODEL_THRESHOLD` no .env

#### Resposta 422 (Payload Inv√°lido)
```
422 Unprocessable Entity: Input should be a valid list
```
**Solu√ß√£o**: Verificar formato JSON - deve ser lista de transa√ß√µes

#### Fallback IA com `needs_keys=true`
```
"needs_keys": true
```
**Solu√ß√£o**: Configurar pelo menos uma API key (`OPENAI_API_KEY` ou `ANTHROPIC_API_KEY`) no .env

#### Feature Flags N√£o Funcionando
```
WARNING: Rules engine desabilitado por feature flag
```
**Solu√ß√£o**: Verificar valores das flags no .env (`ENABLE_DETERMINISTIC_RULES`, `ENABLE_TFIDF_SIMILARITY`, `ENABLE_FALLBACK_AI`)

### Isolamento de Problemas
```bash
# Testar cada engine individualmente
python -m pytest spend_classification/tests/test_rules.py -v
python -m pytest spend_classification/tests/test_similarity.py -v
python -m pytest spend_classification/tests/test_model_adapter.py -v
```

## 19. Guia de Contribui√ß√£o Interna

### Padr√£o de Branches
- **`chore/`**: Limpeza, refatora√ß√£o, configura√ß√£o
- **`feat/`**: Novas funcionalidades
- **`fix/`**: Corre√ß√µes de bugs
- **`docs/`**: Documenta√ß√£o

### Adicionar Novas Regras
1. **Localiza√ß√£o**: `spend_classification/engines/rules.py`
2. **Ordem**: Adicionar em `RulesEngine._setup_default_rules()`
3. **Testes**: Incluir em `spend_classification/tests/test_rules.py`
4. **Impacto**: Verificar ordem de decis√£o no pipeline

### Adicionar Novas Categorias
1. **Constants**: Adicionar em `spend_classification/core/constants.py`
2. **Schemas**: Atualizar `ExpenseCategory` enum
3. **Retreinamento**: Executar `python treinar_modelo.py`
4. **Testes**: Validar com dados de teste

### Atualizar Corpus/Modelo
1. **Backup**: Fazer backup dos modelos atuais e do dataset
   ```bash
   cp modelo_despesas_completo.csv modelo_despesas_completo.csv.backup
   cp -r modelos/ modelos_backup/
   ```

2. **Dados**: Adicionar novos dados em `modelo_despesas_completo.csv` (ou arquivo configurado via `TRAINING_DATA_FILE`)

3. **Retreinamento**: Executar script de treinamento
   ```bash
   # Via script direto
   python treinar_modelo.py
   
   # Ou via pipeline de retreino (recomendado - inclui backup autom√°tico)
   curl -X POST "http://localhost:8080/v1/feedback/pipeline/run-complete"
   ```

4. **Valida√ß√£o**: 
   - Verificar m√©tricas de treinamento (F1-macro, Brier score)
   - Rodar testes automatizados: `python -m pytest spend_classification/tests -v`
   - Validar casos espec√≠ficos atrav√©s dos testes de diagn√≥stico do script
   - Comparar performance com vers√£o anterior

5. **Deploy**: Substituir modelos em produ√ß√£o ap√≥s valida√ß√£o bem-sucedida

## 19. Links √öteis

- **Documenta√ß√£o API**: http://localhost:8080/docs (Swagger UI)
- **ReDoc**: http://localhost:8080/redoc
- **Testes**: `python -m pytest spend_classification/tests -v`

## 20. Changelog

### v1.11.0 - Melhorias no Script de Treinamento
- ‚úÖ **Valida√ß√£o Cruzada Estratificada**: Implementa√ß√£o completa com 5 folds para sele√ß√£o robusta de modelos
- ‚úÖ **Calibra√ß√£o de Probabilidades**: Suporte a CalibratedClassifierCV com LinearSVC para probabilidades calibradas
- ‚úÖ **M√©tricas Avan√ßadas**: Brier score e AUC por classe para avalia√ß√£o de calibra√ß√£o e performance
- ‚úÖ **Oversampling Leve**: Balanceamento inteligente de classes (min_frac=0.7) apenas no treino
- ‚úÖ **Remo√ß√£o Autom√°tica de Classes Raras**: Filtragem autom√°tica de classes com < 2 exemplos
- ‚úÖ **Testes de Diagn√≥stico**: Valida√ß√£o autom√°tica de casos espec√≠ficos ap√≥s treinamento
- ‚úÖ **Sele√ß√£o Autom√°tica de Modelo**: Escolha do melhor modelo baseado em F1-macro m√©dio na valida√ß√£o cruzada
- ‚úÖ **Salvamento de Componentes**: Vectorizer e classifier salvos separadamente para flexibilidade
- ‚úÖ **Limpeza de Texto Aprimorada**: Remo√ß√£o de datas, palavras gen√©ricas e normaliza√ß√£o robusta
- ‚úÖ **Documenta√ß√£o Completa**: Se√ß√£o detalhada sobre script de treinamento no README
- ‚úÖ **Relat√≥rios Detalhados**: Classification report, matriz de confus√£o e m√©tricas por classe
- ‚úÖ **Integra√ß√£o com Pipeline**: Suporte completo ao pipeline de retreino via API

**Principais mudan√ßas**:
- Script de treinamento agora usa valida√ß√£o cruzada estratificada para sele√ß√£o de modelo
- Modelos calibrados garantem probabilidades mais confi√°veis
- Testes de diagn√≥stico validam casos espec√≠ficos automaticamente
- Documenta√ß√£o completa sobre processo de treinamento e m√©tricas

### v1.10.0 - Pipeline Completo de Ingest√£o e Retreino
- ‚úÖ **Pipeline Implementado**: Sistema completo de ingest√£o e retreino funcional
- ‚úÖ **7 Novos Endpoints**: API completa para gerenciar todo o fluxo de dados
- ‚úÖ **Controle de Duplica√ß√£o**: Remo√ß√£o autom√°tica de duplicatas por transactionId
- ‚úÖ **Arquivo de Controle**: Preven√ß√£o de reprocessamento de arquivos
- ‚úÖ **Valida√ß√£o Robusta**: M√∫ltiplas valida√ß√µes de qualidade e integridade
- ‚úÖ **Backup Autom√°tico**: Preserva√ß√£o autom√°tica de dados originais
- ‚úÖ **Integra√ß√£o Completa**: Retreino autom√°tico com treinar_modelo.py
- ‚úÖ **Monitoramento Detalhado**: M√©tricas e status em tempo real
- ‚úÖ **Documenta√ß√£o Swagger**: 7 novos endpoints com documenta√ß√£o completa
- ‚úÖ **Testes Abrangentes**: 24 cen√°rios de teste com 100% de cobertura
- ‚úÖ **README Atualizado**: Se√ß√£o completa sobre pipeline de ingest√£o

### v1.9.0 - Ganchos para Integra√ß√£o de Feedbacks
- ‚úÖ **Servi√ßo de Ingest√£o**: `FeedbackIngestionService` com fun√ß√µes documentadas
- ‚úÖ **Fun√ß√µes preparadas**: `collect_feedbacks()`, `merge_into_model_dataset()`, `write_merged_dataset()`
- ‚úÖ **Valida√ß√£o de estrutura**: Verifica√ß√£o de 14 colunas padr√£o
- ‚úÖ **Documenta√ß√£o completa**: Invariantes, riscos e fluxo de integra√ß√£o
- ‚úÖ **Fun√ß√µes auxiliares**: Listagem de arquivos e valida√ß√£o implementadas
- ‚úÖ **README atualizado**: Se√ß√£o completa sobre pipeline de ingest√£o

### v1.8.0 - API de Feedback
- ‚úÖ **Endpoint /v1/feedback**: API para registro de corre√ß√µes do usu√°rio
- ‚úÖ **Suporte a lote**: Aceita item √∫nico ou array de feedbacks
- ‚úÖ **Persist√™ncia segura**: Append com locks para concorr√™ncia
- ‚úÖ **Mapeamento autom√°tico**: Convers√£o para formato CSV com 14 colunas
- ‚úÖ **Valida√ß√µes completas**: Campos obrigat√≥rios e valida√ß√£o de tipos
- ‚úÖ **Documenta√ß√£o Swagger**: Tags e exemplos completos
- ‚úÖ **Testes automatizados**: Su√≠te completa com 9 cen√°rios de teste
- ‚úÖ **Documenta√ß√£o README**: Se√ß√£o completa com exemplos curl/PowerShell

### v1.7.0 - Docker Compose para Desenvolvimento
- ‚úÖ **Docker Compose**: Configura√ß√£o opcional para desenvolvimento r√°pido
- ‚úÖ **Hot-reload**: Suporte a reload autom√°tico em desenvolvimento
- ‚úÖ **Separa√ß√£o de ambientes**: Base + override para dev vs prod
- ‚úÖ **Paridade Cloud Run**: Configura√ß√£o base compat√≠vel com Cloud Run
- ‚úÖ **Documenta√ß√£o**: Se√ß√£o completa com trade-offs e troubleshooting
- ‚úÖ **Volumes opcionais**: Apenas para desenvolvimento local

### v1.6.0 - Prepara√ß√£o para GCP Cloud Run
- ‚úÖ **Conven√ß√£o de Tags**: Padroniza√ß√£o para registry GCP
- ‚úÖ **Caminhos de Build**: Local (debug) e remoto (produ√ß√£o)
- ‚úÖ **Checklist Cloud Run**: Valida√ß√£o completa de requisitos
- ‚úÖ **Script de Deploy**: Automatiza√ß√£o completa do deploy
- ‚úÖ **Documenta√ß√£o**: Se√ß√£o completa de deploy no GCP
- ‚úÖ **Zero Depend√™ncias Locais**: Imagem totalmente autocontida

### v1.5.0 - Smoke Test do Container
- ‚úÖ **Smoke Test**: Teste automatizado completo do ciclo Docker
- ‚úÖ **Scripts multiplataforma**: Unix (.sh), Windows (.bat/.ps1)
- ‚úÖ **Valida√ß√£o completa**: Build, execu√ß√£o, health check, classifica√ß√£o
- ‚úÖ **Limpeza autom√°tica**: Container sempre parado ao final
- ‚úÖ **Polling inteligente**: Health check com timeout configur√°vel
- ‚úÖ **Valida√ß√£o de campos**: Verifica predictions[0].label e confidence
- ‚úÖ **Documenta√ß√£o**: Se√ß√£o completa com exemplos e troubleshooting

### v1.4.0 - Makefile e Scripts Auxiliares
- ‚úÖ **Makefile**: Targets para desenvolvimento e Docker
- ‚úÖ **Scripts CLI**: Testes automatizados para Unix e Windows
- ‚úÖ **Comandos simplificados**: `make run-api`, `make test`, `make docker-build`
- ‚úÖ **Scripts PowerShell**: Vers√µes avan√ßadas para Windows
- ‚úÖ **Documenta√ß√£o**: Tabela de comandos e equivalentes Windows
- ‚úÖ **Valida√ß√£o autom√°tica**: Scripts verificam campos obrigat√≥rios

### v1.3.0 - Docker e Build Otimizado
- ‚úÖ **Dockerfile**: Imagem otimizada com `python:3.11-slim`
- ‚úÖ **Usu√°rio n√£o-root**: Execu√ß√£o segura como `appuser`
- ‚úÖ **Build otimizado**: `.dockerignore` para reduzir tamanho da imagem
- ‚úÖ **Health check**: Verifica√ß√£o autom√°tica de sa√∫de do container
- ‚úÖ **Modelos**: Copiados para `/models` (paridade com Cloud Run)
- ‚úÖ **Worker √∫nico**: Configurado para 1 worker (ideal para containers)
- ‚úÖ **Documenta√ß√£o**: Se√ß√£o "Rodar com Docker" no README

### v1.2.0 - Prepara√ß√£o para Container
- ‚úÖ **Container Ready**: Aplica√ß√£o preparada para rodar 100% em container
- ‚úÖ **Health Check**: Endpoint `/healthz` retorna `{"status":"ok"}`
- ‚úÖ **Shutdown Gracioso**: Responde a SIGTERM sem pend√™ncias
- ‚úÖ **Vari√°vel PORT**: Servidor usa porta da vari√°vel PORT (default 8080)
- ‚úÖ **MODEL_DIR**: Carregamento de modelos via vari√°vel MODEL_DIR
- ‚úÖ **Degrada√ß√£o Graciosa**: Funciona sem CSVs hist√≥ricos
- ‚úÖ **Feature Flags**: Padr√µes otimizados para container (todos desabilitados)
- ‚úÖ **Documenta√ß√£o**: README atualizado com se√ß√£o de containers

### v1.1.0 - Feature Flags e Fallback IA
- ‚úÖ **Feature Flags**: Controle granular de engines via vari√°veis de ambiente
- ‚úÖ **Fallback IA**: Integra√ß√£o com OpenAI e Anthropic para casos de d√∫vida
- ‚úÖ **TRAINING_DATA_FILE**: Configura√ß√£o flex√≠vel do arquivo de treinamento
- ‚úÖ **Campo needs_keys**: Indica√ß√£o quando faltam API keys para fallback IA
- ‚úÖ **Configura√ß√£o padr√£o**: Regras e TF-IDF desabilitados, Fallback IA habilitado
- ‚úÖ **Valida√ß√£o de API keys**: Verifica√ß√£o autom√°tica na inicializa√ß√£o

### v1.0.0 - Migra√ß√£o para spend_classification
- ‚úÖ **Nova arquitetura**: Pipeline modular com engines especializados
- ‚úÖ **API FastAPI**: Endpoints REST padronizados
- ‚úÖ **Testes automatizados**: 173 testes cobrindo todos os componentes
- ‚úÖ **Thresholds configur√°veis**: Via vari√°veis de ambiente
- ‚úÖ **Documenta√ß√£o consolidada**: README √∫nico como fonte de verdade

### v0.x - Engines Legacy (Arquivados)
- üìÅ **Arquivados**: Engines antigos movidos para `_archive/2024-12/legacy_engines/`
- üìÅ **Testes legacy**: Movidos para `_archive/2024-12/legacy_engines_tests/`
- üîó **Refer√™ncia**: Ver `_archive/` para hist√≥rico completo

---

### v1.9.0 - Melhorias de Normaliza√ß√£o e Integra√ß√£o SerpAPI
- ‚úÖ **Normaliza√ß√£o aprimorada**: Remo√ß√£o de palavras gen√©ricas (pagamento, compra, anuidade, debito, credito, pix)
- ‚úÖ **Limpeza de par√™nteses**: Remo√ß√£o autom√°tica de par√™nteses vazios residuais
- ‚úÖ **Extra√ß√£o de estabelecimento**: M√©todo para extrair nome limpo do estabelecimento
- ‚úÖ **Integra√ß√£o SerpAPI**: Busca autom√°tica de contexto sobre estabelecimentos via SerpAPI
- ‚úÖ **Prompt aprimorado**: Estrutura melhorada com contexto de busca web para AI Fallback
- ‚úÖ **Centraliza√ß√£o .env**: Arquivo `.env.example` criado na raiz com todas as vari√°veis
- ‚úÖ **Remo√ß√£o de caracteres residuais**: Melhoria na normaliza√ß√£o para remover elementos desnecess√°rios
- ‚úÖ **Documenta√ß√£o atualizada**: README com todas as mudan√ßas documentadas

**Principais mudan√ßas**:
- Similarity Engine agora remove palavras gen√©ricas antes de calcular similaridade
- AI Fallback usa SerpAPI para enriquecer contexto quando dispon√≠vel
- Normaliza√ß√£o mais robusta remove par√™nteses vazios e caracteres especiais
- Arquivo `.env.example` dispon√≠vel como template de configura√ß√£o

## üìû Suporte

Para d√∫vidas ou problemas:
1. **Verificar troubleshooting** (se√ß√£o 17)
2. **Executar testes** para isolar problemas
3. **Consultar logs** da aplica√ß√£o
4. **Validar configura√ß√£o** (.env e modelos)

**Status**: ‚úÖ Sistema est√°vel e pronto para produ√ß√£o