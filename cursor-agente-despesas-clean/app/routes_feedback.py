#!/usr/bin/env python3
"""
M√≥dulo de rotas para o endpoint de feedback.

Este m√≥dulo define as rotas da API para registro de feedbacks do usu√°rio,
incluindo documenta√ß√£o Swagger completa.
"""

import os
from typing import List, Optional
from fastapi import APIRouter, HTTPException, Query
from fastapi.responses import JSONResponse

from app.schemas_feedback import (
    FeedbackRequest, 
    FeedbackResponse, 
    FeedbackItem, 
    FeedbackFileInfo
)
from app.services.feedback_store import FeedbackStore
from app.services.feedback_ingestion import FeedbackIngestionService
from app.config import get_feedback_dir

# Configura√ß√µes do servi√ßo
FEEDBACK_DIR = get_feedback_dir()
FEEDBACK_FILENAME_TEMPLATE = os.getenv("FEEDBACK_FILENAME_TEMPLATE", "feedback_%Y-%m-%d.csv")
TZ = os.getenv("TZ")  # Timezone opcional

# Inicializar servi√ßos
feedback_store = FeedbackStore(
    feedback_dir=FEEDBACK_DIR,
    filename_template=FEEDBACK_FILENAME_TEMPLATE,
    timezone=TZ
)

feedback_ingestion = FeedbackIngestionService(
    feedback_dir=FEEDBACK_DIR,
    base_csv=os.getenv("TRAINING_DATA_FILE", "modelo_despesas_completo.csv")
)

# Router para feedback
router = APIRouter(prefix="/v1", tags=["Feedback"])


@router.post(
    "/feedback",
    response_model=FeedbackResponse,
    status_code=201,
    summary="Registrar feedback de corre√ß√£o",
    description="""
    ## üìù **Endpoint de Feedback para Corre√ß√µes do Usu√°rio**
    
    Este endpoint permite registrar corre√ß√µes do usu√°rio em transa√ß√µes classificadas.
    Os dados s√£o salvos em arquivos CSV di√°rios para posterior incorpora√ß√£o ao modelo.
    
    ### üîÑ **Funcionalidades**
    
    - **Suporte a lote**: Aceita item √∫nico ou array de feedbacks
    - **Persist√™ncia segura**: Append com locks para concorr√™ncia
    - **Cria√ß√£o autom√°tica**: Arquivo e cabe√ßalho criados automaticamente
    - **Mapeamento inteligente**: Convers√£o autom√°tica para formato CSV
    
    ### üìä **Mapeamento para CSV**
    
    Os campos s√£o mapeados para as seguintes colunas (nesta ordem):
    
    1. **Aonde Gastou** ‚Üê `description`
    2. **Natureza do Gasto** ‚Üê `category` (vazio se ausente)
    3. **Valor Total** ‚Üê `amount * max(parcelas, 1)`
    4. **Parcelas** ‚Üê `parcelas` (default 1 se ausente)
    5. **No da Parcela** ‚Üê `numero_parcela` (vazio se ausente)
    6. **Valor Unit√°rio** ‚Üê `amount`
    7. **tipo** ‚Üê `source`
    8. **Comp** ‚Üê `comp`
    9. **Data** ‚Üê `date`
    10. **cartao** ‚Üê `card`
    11. **transactionId** ‚Üê `transactionId`
    12. **modelVersion** ‚Üê `modelVersion`
    13. **createdAt** ‚Üê `createdAt` (timestamp atual se ausente)
    14. **flux** ‚Üê `flux`
    
    ### üéØ **Campos Obrigat√≥rios**
    
    - `transactionId`: ID √∫nico da transa√ß√£o
    - `description`: Descri√ß√£o da transa√ß√£o
    - `amount`: Valor unit√°rio (deve ser > 0)
    - `date`: Data no formato ISO
    
    ### üìÅ **Arquivo de Destino**
    
    Os dados s√£o salvos em: `feedbacks/feedback_YYYY-MM-DD.csv`
    
    ### üîí **Comportamento**
    
    - **Sem deduplica√ß√£o**: TransactionIds repetidos s√£o registrados novamente
    - **Concorr√™ncia segura**: Locks por arquivo evitam corrup√ß√£o
    - **Valores padr√£o**: Campos opcionais ausentes viram vazio no CSV
    - **Formato decimal**: Valores salvos com ponto decimal (padr√£o)
    
    ### üö® **C√≥digos de Resposta**
    
    - `201`: Feedback salvo com sucesso
    - `400`: Dados inv√°lidos ou campos obrigat√≥rios ausentes
    - `422`: Erro de valida√ß√£o nos dados
    - `500`: Erro interno do servidor
    """,
    responses={
        201: {
            "description": "Feedback salvo com sucesso",
            "content": {
                "application/json": {
                    "example": {
                        "saved_rows": 3,
                        "file_path": "feedbacks/feedback_2024-01-01.csv",
                        "columns": [
                            "Aonde Gastou",
                            "Natureza do Gasto", 
                            "Valor Total",
                            "Parcelas",
                            "No da Parcela",
                            "Valor Unit√°rio",
                            "tipo",
                            "Comp",
                            "Data",
                            "cartao",
                            "transactionId",
                            "modelVersion",
                            "createdAt",
                            "flux"
                        ]
                    }
                }
            }
        },
        400: {
            "description": "Dados inv√°lidos",
            "content": {
                "application/json": {
                    "example": {
                        "detail": "Lista de feedbacks n√£o pode estar vazia"
                    }
                }
            }
        },
        422: {
            "description": "Erro de valida√ß√£o",
            "content": {
                "application/json": {
                    "example": {
                        "detail": [
                            {
                                "loc": ["body", "feedback", 0, "amount"],
                                "msg": "ensure this value is greater than 0",
                                "type": "value_error.number.not_gt"
                            }
                        ]
                    }
                }
            }
        },
        500: {
            "description": "Erro interno do servidor",
            "content": {
                "application/json": {
                    "example": {
                        "detail": "Erro ao salvar feedbacks: [detalhes do erro]"
                    }
                }
            }
        }
    }
)
async def create_feedback(request: FeedbackRequest):
    """
    üéØ **Registra feedback de corre√ß√£o do usu√°rio**
    
    Salva corre√ß√µes em arquivo CSV di√°rio para posterior incorpora√ß√£o ao modelo.
    """
    try:
        # Normalizar entrada para lista
        if isinstance(request.feedback, FeedbackItem):
            feedback_items = [request.feedback]
        else:
            feedback_items = request.feedback
        
        if not feedback_items:
            raise HTTPException(
                status_code=400, 
                detail="Lista de feedbacks n√£o pode estar vazia"
            )
        
        # Converter Pydantic models para dict
        feedback_dicts = []
        for item in feedback_items:
            # Adicionar timestamp atual se createdAt n√£o especificado
            item_dict = item.dict()
            if not item_dict.get("createdAt"):
                from datetime import datetime
                item_dict["createdAt"] = datetime.now().isoformat()
            
            feedback_dicts.append(item_dict)
        
        # Salvar feedbacks
        result = feedback_store.save_feedbacks(feedback_dicts)
        
        return FeedbackResponse(**result)
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=500, 
            detail=f"Erro ao salvar feedbacks: {str(e)}"
        )


@router.get(
    "/feedback/file-info",
    response_model=FeedbackFileInfo,
    summary="Informa√ß√µes sobre arquivo de feedback",
    description="""
    ## üìÅ **Informa√ß√µes sobre Arquivo de Feedback**
    
    Retorna informa√ß√µes detalhadas sobre o arquivo de feedback de uma data espec√≠fica.
    
    ### üìä **Informa√ß√µes Retornadas**
    
    - **Arquivo**: Nome e caminho do arquivo
    - **Exist√™ncia**: Se o arquivo existe no sistema
    - **Tamanho**: Tamanho em bytes (se existe)
    - **Modifica√ß√£o**: Data da √∫ltima modifica√ß√£o (se existe)
    - **Cabe√ßalho**: Se tem cabe√ßalho correto (se existe)
    - **Colunas**: Lista das colunas esperadas
    
    ### üéØ **Par√¢metros**
    
    - `date`: Data no formato YYYY-MM-DD (opcional, usa hoje se n√£o especificado)
    
    ### üìù **Exemplos**
    
    - `GET /v1/feedback/file-info` - Informa√ß√µes do arquivo de hoje
    - `GET /v1/feedback/file-info?date=2024-01-01` - Informa√ß√µes do arquivo de 01/01/2024
    """,
    responses={
        200: {
            "description": "Informa√ß√µes do arquivo",
            "content": {
                "application/json": {
                    "example": {
                        "filename": "feedback_2024-01-01.csv",
                        "file_path": "feedbacks/feedback_2024-01-01.csv",
                        "exists": True,
                        "columns": ["Aonde Gastou", "Natureza do Gasto", "Valor Total"],
                        "size_bytes": 2048,
                        "modified": "2024-01-01T12:00:00",
                        "has_header": True
                    }
                }
            }
        },
        400: {
            "description": "Data inv√°lida",
            "content": {
                "application/json": {
                    "example": {
                        "detail": "Data deve estar no formato YYYY-MM-DD"
                    }
                }
            }
        }
    }
)
async def get_feedback_file_info(
    date: Optional[str] = Query(
        None, 
        description="Data no formato YYYY-MM-DD (opcional, usa hoje se n√£o especificado)",
        example="2024-01-01"
    )
):
    """
    üìÅ **Obt√©m informa√ß√µes sobre arquivo de feedback**
    
    Retorna detalhes sobre o arquivo de feedback de uma data espec√≠fica.
    """
    try:
        info = feedback_store.get_feedback_file_info(date)
        return FeedbackFileInfo(**info)
        
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(
            status_code=500, 
            detail=f"Erro ao obter informa√ß√µes do arquivo: {str(e)}"
        )


# =============================================================================
# ENDPOINTS DO PIPELINE DE INGEST√ÉO E RETREINO
# =============================================================================

@router.get(
    "/feedback/pipeline/status",
    summary="Status do Pipeline de Ingest√£o",
    description="""
    ## üîÑ **Status do Pipeline de Ingest√£o de Feedbacks**
    
    Retorna informa√ß√µes sobre o estado atual do pipeline de ingest√£o e retreino.
    
    ### üìä **Informa√ß√µes Retornadas**
    
    - **Arquivos de feedback**: Quantidade e status
    - **Arquivos processados**: Lista de arquivos j√° processados
    - **Modelos**: Timestamps e status dos modelos
    - **Backups**: Informa√ß√µes sobre backups dispon√≠veis
    - **M√©tricas**: Estat√≠sticas do pipeline
    
    ### üéØ **Uso**
    
    Use este endpoint para monitorar o estado do sistema antes de executar
    opera√ß√µes de ingest√£o ou retreino.
    """
)
async def get_pipeline_status():
    """Obt√©m status completo do pipeline de ingest√£o"""
    try:
        # Informa√ß√µes sobre arquivos de feedback
        feedback_files = feedback_ingestion.get_feedback_files()
        processed_files = feedback_ingestion.get_processed_files()
        
        # Informa√ß√µes sobre modelos
        model_timestamps = feedback_ingestion.get_model_timestamps()
        
        # Informa√ß√µes sobre backups
        backup_files = feedback_ingestion.get_backup_files()
        
        # Informa√ß√µes sobre dataset base
        base_csv = feedback_ingestion.base_csv
        base_exists = os.path.exists(base_csv)
        base_info = {}
        if base_exists:
            base_info = feedback_ingestion.get_dataset_info(base_csv)
        
        return {
            "pipeline_status": "operational",
            "feedback_files": {
                "total_found": len(feedback_files),
                "files": [str(f) for f in feedback_files],
                "processed_count": len(processed_files),
                "processed_files": list(processed_files),
                "pending_count": len(feedback_files) - len(processed_files)
            },
            "models": {
                "directory": "modelos",
                "count": len(model_timestamps),
                "files": model_timestamps,
                "last_updated": max(model_timestamps.values()) if model_timestamps else None
            },
            "backups": {
                "count": len(backup_files),
                "files": backup_files
            },
            "dataset_base": {
                "file": base_csv,
                "exists": base_exists,
                "info": base_info
            },
            "timestamp": "2024-01-15T12:00:00Z"
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Erro ao obter status do pipeline: {str(e)}"
        )


@router.post(
    "/feedback/pipeline/collect",
    summary="Coletar Feedbacks para Processamento",
    description="""
    ## üì• **Coleta de Feedbacks para Processamento**
    
    Coleta todos os arquivos de feedback n√£o processados e os prepara para
    integra√ß√£o com o dataset principal.
    
    ### üîÑ **Processo**
    
    1. **Lista arquivos**: Encontra todos os arquivos `feedback_*.csv`
    2. **Filtra novos**: Remove arquivos j√° processados
    3. **Valida estrutura**: Verifica se cada arquivo tem 14 colunas
    4. **Remove duplicatas**: Elimina duplicatas por transactionId
    5. **Marca processados**: Atualiza lista de arquivos processados
    
    ### üìä **Resposta**
    
    - **Arquivos processados**: Lista de arquivos coletados
    - **Registros coletados**: Total de registros √∫nicos
    - **Duplicatas removidas**: Estat√≠sticas de limpeza
    - **Pr√≥ximos passos**: Sugest√µes para continuar o pipeline
    
    ### ‚ö†Ô∏è **Importante**
    
    - Arquivos s√£o marcados como processados ap√≥s coleta bem-sucedida
    - Use `/feedback/pipeline/clear-processed` para reprocessar arquivos
    - Opera√ß√£o √© idempotente (seguro executar m√∫ltiplas vezes)
    """
)
async def collect_feedbacks():
    """Coleta feedbacks n√£o processados"""
    try:
        feedbacks = feedback_ingestion.collect_feedbacks_with_control()
        
        total_records = sum(len(df) for df in feedbacks)
        
        return {
            "success": True,
            "operation": "collect_feedbacks",
            "results": {
                "files_collected": len(feedbacks),
                "total_records": total_records,
                "files": [f"feedback_YYYY-MM-DD.csv" for _ in feedbacks]  # Placeholder
            },
            "next_steps": [
                "Execute /feedback/pipeline/merge para integrar ao dataset",
                "Execute /feedback/pipeline/retrain para retreinar modelos"
            ],
            "timestamp": "2024-01-15T12:00:00Z"
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Erro na coleta de feedbacks: {str(e)}"
        )


@router.post(
    "/feedback/pipeline/merge",
    summary="Mesclar Feedbacks com Dataset Principal",
    description="""
    ## üîó **Mesclagem de Feedbacks com Dataset Principal**
    
    Integra os feedbacks coletados ao dataset principal para preparar
    dados para retreino dos modelos.
    
    ### üîÑ **Processo**
    
    1. **Carrega dataset base**: L√™ arquivo principal de treinamento
    2. **Coleta feedbacks**: Busca feedbacks n√£o processados
    3. **Valida integra√ß√£o**: Verifica compatibilidade e qualidade
    4. **Mescla dados**: Concatena feedbacks ao final do dataset
    5. **Valida resultado**: Confirma estrutura e integridade
    
    ### üìä **Valida√ß√µes Executadas**
    
    - **Estrutura de colunas**: Compatibilidade entre base e feedbacks
    - **Duplicatas**: Detec√ß√£o de transactionIds duplicados
    - **Qualidade**: Valores nulos e negativos em campos cr√≠ticos
    - **Balanceamento**: An√°lise de distribui√ß√£o de categorias
    
    ### üìà **M√©tricas Retornadas**
    
    - **Registros base**: Quantidade no dataset original
    - **Registros feedback**: Quantidade de feedbacks integrados
    - **Duplicatas encontradas**: TransactionIds j√° existentes
    - **Problemas de qualidade**: Issues detectados nos dados
    
    ### ‚ö†Ô∏è **Importante**
    
    - Dataset base deve existir e ser v√°lido
    - Opera√ß√£o cria backup autom√°tico antes de modificar
    - Use `/feedback/pipeline/backup/list` para ver backups
    """
)
async def merge_feedbacks():
    """Mescla feedbacks com dataset principal"""
    try:
        merged_df = feedback_ingestion.merge_into_model_dataset()
        
        return {
            "success": True,
            "operation": "merge_dataset",
            "results": {
                "total_records": len(merged_df),
                "dataset_file": feedback_ingestion.base_csv,
                "backup_created": True
            },
            "next_steps": [
                "Execute /feedback/pipeline/retrain para retreinar modelos",
                "Execute /feedback/pipeline/validate para validar qualidade"
            ],
            "timestamp": "2024-01-15T12:00:00Z"
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Erro na mesclagem: {str(e)}"
        )


@router.post(
    "/feedback/pipeline/retrain",
    summary="Retreinar Modelos com Dados Atualizados",
    description="""
    ## ü§ñ **Retreino de Modelos com Dados Atualizados**
    
    Executa o retreino completo dos modelos usando o dataset atualizado
    com os feedbacks integrados.
    
    ### üîÑ **Processo**
    
    1. **Verifica modelos**: Obt√©m timestamps dos modelos atuais
    2. **Executa treinamento**: Chama `treinar_modelo.py` com dataset atualizado
    3. **Monitora progresso**: Acompanha execu√ß√£o com timeout de 10min
    4. **Valida resultados**: Verifica se modelos foram atualizados
    5. **Testa qualidade**: Valida funcionalidade dos novos modelos
    
    ### üìä **Modelos Retreinados**
    
    - **modelo_natureza_do_gasto.pkl**: Classifica√ß√£o de categorias
    - **modelo_comp.pkl**: Classifica√ß√£o de compartilhamento
    - **modelo_parcelas.pkl**: Predi√ß√£o de parcelas
    
    ### üîç **Valida√ß√µes de Qualidade**
    
    - **Carregamento**: Modelos podem ser carregados corretamente
    - **M√©todos**: Presen√ßa de m√©todos `predict` e `predict_proba`
    - **Teste funcional**: Predi√ß√µes com dados de exemplo
    - **Tamanho**: Verifica√ß√£o de tamanho dos arquivos
    
    ### ‚ö†Ô∏è **Importante**
    
    - Timeout de 10 minutos para evitar travamentos
    - Vari√°veis de ambiente s√£o configuradas automaticamente
    - Logs detalhados s√£o capturados e retornados
    - Opera√ß√£o pode ser demorada dependendo do tamanho dos dados
    """
)
async def retrain_models():
    """Retreina modelos com dados atualizados"""
    try:
        result = feedback_ingestion.trigger_model_retraining(feedback_ingestion.base_csv)
        
        if result['success']:
            return {
                "success": True,
                "operation": "retrain_models",
                "results": {
                    "updated_models": result['updated_models'],
                    "models_before": result['models_before'],
                    "models_after": result['models_after'],
                    "quality_results": result['quality_results']
                },
                "training_output": result['training_output'],
                "next_steps": [
                    "Modelos atualizados com sucesso",
                    "Execute /feedback/pipeline/validate para validar qualidade",
                    "Execute /feedback/pipeline/status para verificar estado"
                ],
                "timestamp": "2024-01-15T12:00:00Z"
            }
        else:
            raise HTTPException(
                status_code=500,
                detail=f"Erro no retreino: {result['error']}"
            )
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Erro no retreino dos modelos: {str(e)}"
        )


@router.post(
    "/feedback/pipeline/run-complete",
    summary="Executar Pipeline Completo",
    description="""
    ## üöÄ **Pipeline Completo de Ingest√£o e Retreino**
    
    Executa todo o pipeline de ingest√£o de feedbacks em uma √∫nica opera√ß√£o:
    coleta ‚Üí mesclagem ‚Üí escrita ‚Üí retreino.
    
    ### üîÑ **Fluxo Completo**
    
    1. **Coleta**: Busca feedbacks n√£o processados
    2. **Mesclagem**: Integra com dataset principal
    3. **Escrita**: Salva dataset consolidado com backup
    4. **Retreino**: Executa treinamento dos modelos
    5. **Valida√ß√£o**: Confirma qualidade dos resultados
    
    ### üìä **M√©tricas Detalhadas**
    
    - **Feedbacks coletados**: Quantidade de arquivos processados
    - **Registros integrados**: Total de registros adicionados
    - **Modelos atualizados**: Lista de modelos retreinados
    - **Tempo de execu√ß√£o**: Dura√ß√£o de cada etapa
    - **Qualidade**: Resultados das valida√ß√µes
    
    ### ‚ö†Ô∏è **Importante**
    
    - **Opera√ß√£o longa**: Pode levar v√°rios minutos para completar
    - **Backup autom√°tico**: Dataset original √© preservado
    - **Rollback**: Em caso de erro, sistema pode ser restaurado
    - **Monitoramento**: Use `/feedback/pipeline/status` para acompanhar
    
    ### üéØ **Quando Usar**
    
    - **Integra√ß√£o di√°ria**: Processar feedbacks acumulados
    - **Retreino semanal**: Atualizar modelos regularmente
    - **Deploy**: Preparar sistema para produ√ß√£o
    - **Manuten√ß√£o**: Opera√ß√£o de manuten√ß√£o programada
    """
)
async def run_complete_pipeline():
    """Executa pipeline completo de ingest√£o e retreino"""
    try:
        result = feedback_ingestion.run_complete_pipeline()
        
        return {
            "success": result['success'],
            "operation": "complete_pipeline",
            "steps_completed": result['steps_completed'],
            "errors": result['errors'],
            "metrics": result['metrics'],
            "timestamp": "2024-01-15T12:00:00Z"
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Erro no pipeline completo: {str(e)}"
        )


@router.get(
    "/feedback/pipeline/backup/list",
    summary="Listar Backups Dispon√≠veis",
    description="""
    ## üíæ **Lista de Backups Dispon√≠veis**
    
    Retorna lista de todos os backups de dataset dispon√≠veis,
    ordenados por data de cria√ß√£o (mais recentes primeiro).
    
    ### üìä **Informa√ß√µes dos Backups**
    
    - **Arquivo**: Nome do arquivo de backup
    - **Data de cria√ß√£o**: Timestamp de quando foi criado
    - **Tamanho**: Tamanho do arquivo em bytes
    - **Status**: Se o arquivo ainda existe
    
    ### üîß **Opera√ß√µes Dispon√≠veis**
    
    - **Restaurar**: Use backup para restaurar dataset
    - **Limpar**: Remove backups antigos automaticamente
    - **Validar**: Verifica integridade dos backups
    """
)
async def list_backups():
    """Lista backups dispon√≠veis"""
    try:
        backup_files = feedback_ingestion.get_backup_files()
        
        backup_info = []
        for backup_file in backup_files:
            if os.path.exists(backup_file):
                stat = os.stat(backup_file)
                backup_info.append({
                    "file": backup_file,
                    "created": stat.st_mtime,
                    "size": stat.st_size,
                    "exists": True
                })
            else:
                backup_info.append({
                    "file": backup_file,
                    "created": None,
                    "size": 0,
                    "exists": False
                })
        
        return {
            "success": True,
            "backups": backup_info,
            "count": len(backup_info),
            "timestamp": "2024-01-15T12:00:00Z"
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Erro ao listar backups: {str(e)}"
        )


@router.post(
    "/feedback/pipeline/clear-processed",
    summary="Limpar Lista de Arquivos Processados",
    description="""
    ## üóëÔ∏è **Limpeza de Arquivos Processados**
    
    Remove a lista de arquivos processados, permitindo reprocessamento
    de todos os arquivos de feedback.
    
    ### ‚ö†Ô∏è **CUIDADO**
    
    Esta opera√ß√£o permite reprocessar arquivos j√° processados, o que pode
    causar duplica√ß√£o de dados se executado sem cuidado.
    
    ### üéØ **Quando Usar**
    
    - **Desenvolvimento**: Durante testes e desenvolvimento
    - **Corre√ß√£o de bugs**: Ap√≥s corre√ß√£o de problemas no processamento
    - **Manuten√ß√£o**: Para reprocessar dados com nova l√≥gica
    - **Reset**: Para reiniciar completamente o pipeline
    
    ### üîÑ **Pr√≥ximos Passos**
    
    Ap√≥s limpar a lista, execute `/feedback/pipeline/collect` para
    reprocessar todos os arquivos de feedback.
    """
)
async def clear_processed_files():
    """Limpa lista de arquivos processados"""
    try:
        feedback_ingestion.clear_processed_files()
        
        return {
            "success": True,
            "operation": "clear_processed_files",
            "message": "Lista de arquivos processados foi limpa",
            "next_steps": [
                "Execute /feedback/pipeline/collect para reprocessar arquivos",
                "Execute /feedback/pipeline/status para verificar estado"
            ],
            "timestamp": "2024-01-15T12:00:00Z"
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Erro ao limpar arquivos processados: {str(e)}"
        )
